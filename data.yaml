title: The Agent Protocol Tech Tree
subtitle: How open standards for AI agents emerge layer by layer
details: |
  Open protocols emerge when decentralized parties benefit from speaking the same language.
  If your software will be used more when it outputs data that other software can read,
  and reads data that other software produces, all tools tend to converge on a common format.
  AI agents are currently incentivized to converge in this way, and are rapidly exploring
  and adopting standards. This tool explores
  the standards they are converging on and why each layer came to be.


# ── Tree ──────────────────────────────────────────────────────────────
# Defines hierarchy and visual layout.  Nesting = parent → child.
# extra_cols:     additional columns beyond default (first_parent_col + 1).
# extra_parents:  additional parent connections drawn on the tree.
# Column formula: first_parent_col + 1 + extra_cols (default 0); roots with no parents: 0.
# Sibling order controls vertical positioning within a column.
#
# Clusters are first-class tree nodes with `cluster: true` and `items:`.
# They render as dashed-outline group boxes containing their items.
# Both clusters and their individual items can have parent/child arrows.

tree:
  - id: c-foundations
    cluster: true
    label: Model building standards
    description: >-
      These are the low-level file formats and conventions that let open weight model
      move between training, distribution, and inference.
      None were designed by a standards body; each emerged because model publishers
      and runtime authors converged on the same artifacts.
    items:
      - id: tokenizers
      - id: weight-formats
      - id: embeddings
      - id: chat-templates
    children:
      - id: inference-api
        children:
          - id: tool-calling
            children:
              - id: mcp
                children:
                  - id: mcp-apps
              - id: standard-tool-surfaces
                children:
              - id: agent-loop
                extra_cols: 1
                extra_parents: [standard-tools]
                children:
                  - id: c-context-management
                    cluster: true
                    display: node
                    label: Context Management
                    description: >-
                      As agents engage more with the world, they need ways to fetch updated information
                      about how to handle specific situations.
                    items:
                      - id: agents-md
                      - id: llms-txt
                      - id: agent-skills
                        children:
                          - id: agent-skills-discovery
                          - id: agent-skills-registries
                      - id: interoperable-memory
                  - id: c-interagent
                    cluster: true
                    display: node
                    label: Inter-agent Coordination
                    description: >-
                      The desire to automate large enterprises (or to sell services to them) drives
                      protocols for agents within an enterprise to coordinate their work, potentially across vendors;
                      analogous to existing service discovery layers within enterprises.
                    items:
                      - id: agent-card
                        children:
                          - id: a2a
                          - id: agent-registries
                      - id: agent-lingua
                  - id: c-trust
                    cluster: true
                    display: node
                    label: Trust & Delegation
                    description: >-
                      Agents are agents of someone — they need to be able to do things reliably
                      on behalf of their owners, using some but not all of the owner's capabilities.
                      Protocols that allow agents to do specific trusted tasks lead to standards
                      for more general capability delegation.
                    items:
                      - id: c-agent-identity
                        cluster: true
                        display: node
                        label: Agent Identity
                        description: >-
                          Agents acting on behalf of users need to be able to prove they are who
                          they say they are so they can enter contracts, make representations,
                          or otherwise be trusted.
                        children:
                          - id: web-bot-auth
                          - id: visa-tap
                      - id: c-commerce
                        cluster: true
                        display: node
                        label: Commerce
                        description: >-
                          As agents become the front door to the web, the e-commerce world wants to
                          make sure they can shop for things and pay for them.
                        children:
                          - id: ucp
                          - id: ap2
                      - id: intent-mandates
                      - id: agent-audit

# ── Technologies ────────────────────────────────────────────────────
# unlock.state: locked | unlocked (default unlocked).
# unlock.class: foundational | frontier (determines overlay icon).

technologies:

  # ── Foundations (locked by default; stone-age unlocks) ─────────────
  - id: tokenizers
    toc_group: 1
    title: Tokenizers
    icon_alt: "tok"
    tagline: Portable text-to-token boundary
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "Hugging Face Tokenizers", url: "https://github.com/huggingface/tokenizers" }
        - { label: "SentencePiece", url: "https://github.com/google/sentencepiece" }
      what_it_solves: >-
        Model publishers and runtimes must agree on a shared on-disk artifact with identical encode/decode semantics.
      how_its_standardizing: >-
        Converged through de facto artifacts (vocab/merges, SentencePiece models,
        tokenizer.json) adopted by model publishers and runtimes rather than a
        formal standards body.
      virtuous_cycle:
        - "Model publishers ship a tokenizer artifact so downstream users can run the model."
        - "Runtime/tooling authors implement the common artifacts to support many models."
        - "New models choose widely supported tokenizer formats to maximize portability."
    animation:
      actors:
        - id: repo
          label: Model Repo
          type: repo
        - id: runtime
          label: Runtime / Server
          type: server
      scenes:
        - title: BPE artifacts (vocab + merges)
          description: >-
            Many tokenizers standardize as a pair of files. Runtimes must interpret
            them identically so the same text produces the same token ids.
          actors_visible: [repo, runtime]
          messages:
            - from: runtime
              to: repo
              label: Fetch vocab.json
              json_preview: 'GET /vocab.json'
            - from: repo
              to: runtime
              label: vocab.json
              json_preview: '{"l":0,"o":1,"w":2,"lo":3,"low":4,"er":5,"lower":6}'
            - from: runtime
              to: repo
              label: Fetch merges.txt
              json_preview: 'GET /merges.txt'
            - from: repo
              to: runtime
              label: merges.txt
              json_preview: 'l o\nlo w\nlow er'
            - from: runtime
              to: repo
              label: Deterministic tokenize()
              json_preview: 'tokenize("lower") -> [6]'

        - title: SentencePiece model file
          description: >-
            Other ecosystems converge on a single binary artifact (SentencePiece).
            The runtime only needs the shared loader to get identical pieces + ids.
          actors_visible: [repo, runtime]
          sparkle: true
          messages:
            - from: runtime
              to: repo
              label: Fetch tokenizer.model
              json_preview: 'GET /tokenizer.model'
            - from: repo
              to: runtime
              label: SentencePiece model (binary)
              json_preview: 'pieces=["▁Hello","▁world","!"] ids=[101,102,7]'

        - title: tokenizer.json as a unified portability target
          description: >-
            Some publishers ship tokenizer.json so many runtimes can load one format.
            This becomes a de facto interchange artifact across tools.
          actors_visible: [repo, runtime]
          sparkle: true
          messages:
            - from: runtime
              to: repo
              label: Fetch tokenizer.json
              json_preview: 'GET /tokenizer.json'
            - from: repo
              to: runtime
              label: tokenizer.json (subset)
              json_preview: '{"model":{"type":"BPE"},"pre_tokenizer":{"type":"Whitespace"}}'
            - from: runtime
              to: repo
              label: Same artifact, same ids
              json_preview: 'tokenize("hello world") -> [0,1]'

  - id: weight-formats
    toc_group: 1
    title: Weight Formats
    icon_alt: "w"
    tagline: Safe model distribution
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "safetensors", url: "https://github.com/huggingface/safetensors" }
        - { label: "GGUF / llama.cpp", url: "https://github.com/ggerganov/llama.cpp" }
      what_it_solves: >-
        A safe, fast way to distribute model tensors across frameworks and runtimes.
      how_its_standardizing: >-
        De facto convergence on formats like safetensors (safety/perf) and GGUF
        (local inference ecosystem), driven by tool support and publishing norms.
      virtuous_cycle:
        - "Publishers pick formats that load everywhere with minimal risk."
        - "Runtimes support formats that unlock the largest model catalog."
        - "Converters/quantizers flourish once a stable on-disk format is common."

  - id: embeddings
    toc_group: 1
    title: Embeddings
    icon_alt: "vec"
    tagline: Universal vector interface
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "Standard", url: "https://opensearch.org/docs/latest/search-plugins/knn/" }
      what_it_solves: >-
        A universal "vector + metadata" interface enabling retrieval, semantic search,
        and RAG pipelines regardless of the embedding model or vector store.
      how_its_standardizing: >-
        Converged by API similarity across vector DBs and common client expectations
        (float[] vectors, metadata filters, upsert/query) rather than a single spec.
      virtuous_cycle:
        - "Apps rely on a stable vector interface; swapping stores/models becomes easy."
        - "DBs adopt common ops (upsert/query/filter) to capture the same client ecosystem."
        - "Model providers target vector-friendly shapes to plug into common retrieval stacks."

  - id: chat-templates
    toc_group: 1
    title: Chat Templates
    icon_alt: "msg"
    tagline: Portable conversation format
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "Standard", url: "https://huggingface.co/docs/transformers/main/chat_templating" }
      what_it_solves: >-
        A portable way to represent multi-turn conversations and serialize them into
        model-specific token sequences correctly.
      how_its_standardizing: >-
        Dataset schemas converged on role/content turns; chat template metadata
        (e.g., in tokenizers/configs) enabled generic chat UIs to support many models.
      virtuous_cycle:
        - "Apps can target a consistent message schema across models."
        - "Model publishers ship templates so generic clients can format prompts correctly."
        - "Evaluation/training pipelines reuse the same role/content structure at scale."

  # ── Inference ─────────────────────────────────────────────────────
  - id: inference-api
    title: Inference API
    icon_alt: ">_"
    tagline: A stable way to talk to any model
    detail:
      links:
        - { label: "Standard", url: "https://platform.openai.com/docs/api-reference/chat" }
        - { label: "Ollama compatibility", url: "https://github.com/ollama/ollama/blob/main/docs/openai.md" }
        - { label: "OpenRouter", url: "https://openrouter.ai/docs/quickstart" }
      what_it_solves: >-
        Applications needed a consistent way to send prompts to language
        models and receive responses — without rewriting code for every
        provider. The chat completions API shape gave developers a single
        interface to target, making LLMs a reliable, swappable component.
      how_its_standardizing: >-
        OpenAI's Chat Completions API (March 2023) became the reference
        design for chat-shaped request/response. Many SDKs, gateways, and
        open-source servers (Ollama, vLLM, llama.cpp) expose OpenAI-compatible
        endpoints. Aggregators like OpenRouter expose hundreds of models behind
        the same API. New entrants like DeepSeek ship compatible APIs from
        day one to tap into the existing ecosystem immediately.
      virtuous_cycle:
        - "App makers target one interface and can switch providers with minimal changes."
        - "Model hosts gain adoption by being drop-in compatible with existing clients."
        - "Tooling (SDKs, gateways, proxies) compounds around the common shape."
    animation:
      actors:
        - id: app
          label: Your App
          type: app
        - id: openai
          label: OpenAI
          type: server
        - id: openrouter
          label: OpenRouter
          type: server
        - id: ollama
          label: Ollama (Local)
          type: server
        - id: deepseek
          label: DeepSeek
          type: server
      scenes:
        - title: App talks to a model provider
          description: >-
            Your application sends a chat completion request to OpenAI
            using the standard message format.
          actors_visible: [app, openai]
          messages:
            - from: app
              to: openai
              label: Chat prompt
              json_preview: '{"model":"gpt-4","messages":[{"role":"user","content":"Hello"}]}'
              json_full: |
                POST /v1/chat/completions
                {
                  "model": "gpt-4",
                  "messages": [
                    {"role": "user", "content": "Hello, how are you?"}
                  ],
                  "temperature": 0.7,
                  "max_tokens": 256
                }
            - from: openai
              to: app
              label: Completion
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hi there!"}}]}'
              json_full: |
                {
                  "id": "chatcmpl-abc123",
                  "object": "chat.completion",
                  "model": "gpt-4",
                  "choices": [{
                    "index": 0,
                    "message": {
                      "role": "assistant",
                      "content": "Hi there! How can I help you today?"
                    },
                    "finish_reason": "stop"
                  }],
                  "usage": {
                    "prompt_tokens": 12,
                    "completion_tokens": 9,
                    "total_tokens": 21
                  }
                }
        - title: Same code, any model via aggregator
          description: >-
            Switch to OpenRouter and access hundreds of models from
            different providers — the request and response shape stay the same.
          actors_visible: [app, openrouter]
          sparkle: true
          messages:
            - from: app
              to: openrouter
              label: Same format
              json_preview: '{"model":"anthropic/claude-sonnet-4","messages":[{"role":"user","content":"Hello"}]}'
            - from: openrouter
              to: app
              label: Same shape response
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hello!"}}]}'
        - title: Even works locally
          description: >-
            Ollama runs models on your own machine — and speaks the
            same API. One interface, every model.
          actors_visible: [app, ollama]
          sparkle: true
          messages:
            - from: app
              to: ollama
              label: Same format, locally
              json_preview: '{"model":"llama3","messages":[{"role":"user","content":"Hello"}]}'
            - from: ollama
              to: app
              label: Same shape response
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hey there!"}}]}'
        - title: New models launch pre-compatible
          description: >-
            When DeepSeek launched its R1 model, it shipped an
            OpenAI-compatible API from day one — instant access for
            every app already targeting the standard.
          actors_visible: [app, deepseek]
          sparkle: true
          messages:
            - from: app
              to: deepseek
              label: Same format, new model
              json_preview: '{"model":"deepseek-reasoner","messages":[{"role":"user","content":"Hello"}]}'
            - from: deepseek
              to: app
              label: Same shape response
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hello! How can I help?"}}]}'

  # ── Tool Calling ──────────────────────────────────────────────────
  - id: tool-calling
    title: Tool Calling
    icon_alt: "f(x)"
    tagline: Models that can take action
    detail:
      links:
        - { label: "Launch", url: "https://openai.com/index/function-calling-and-other-api-updates/" }
        - { label: "Standard", url: "https://platform.openai.com/docs/guides/function-calling" }
      what_it_solves: >-
        Language models can only generate text — but applications need
        them to take real actions like searching the web, reading files,
        or calling APIs. Tool calling lets a model emit structured
        "call this function" requests, and then continue after the app
        executes them. Tool definitions use JSON Schema-like structures,
        making tools portable and machine-readable across providers.
      how_its_standardizing: >-
        OpenAI introduced "function calling" in June 2023, later
        generalized to "tool calling." Other providers rapidly adopted
        the same pattern. Standardization is de facto: JSON Schema-inspired
        signatures and tool-call/result message roles work across providers,
        though implementations vary slightly in supported schema features.
      virtuous_cycle:
        - "App makers expose capabilities once and reuse them across many models."
        - "Model makers support tool calling to be useful in real workflows, not just chat."
        - "Tool ecosystems emerge because definitions are machine-readable and reusable."
    animation:
      actors:
        - id: app
          label: Your App
          type: app
        - id: model
          label: LLM
          type: model
      scenes:
        - title: App provides tools to the model
          description: >-
            The app sends a prompt along with tool definitions
            describing what functions are available.
          actors_visible: [app, model]
          messages:
            - from: app
              to: model
              label: Prompt + tool definitions
              json_preview: '{"messages":[...],"tools":[{"type":"function","function":{"name":"search"}}]}'
              json_full: |
                POST /v1/chat/completions
                {
                  "model": "gpt-4",
                  "messages": [
                    {"role": "user", "content": "What's the weather in Boston?"}
                  ],
                  "tools": [{
                    "type": "function",
                    "function": {
                      "name": "get_weather",
                      "description": "Get current weather for a location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {"type": "string"}
                        },
                        "required": ["location"]
                      }
                    }
                  }]
                }
        - title: Model requests a tool call
          description: >-
            Instead of answering directly, the model emits a structured
            tool call — requesting the app to execute a function.
          actors_visible: [app, model]
          messages:
            - from: model
              to: app
              label: tool_call
              json_preview: '{"tool_calls":[{"function":{"name":"get_weather","arguments":"{\"location\":\"Boston\"}"}}]}'
              json_full: |
                {
                  "choices": [{
                    "message": {
                      "role": "assistant",
                      "tool_calls": [{
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_weather",
                          "arguments": "{\"location\": \"Boston, MA\"}"
                        }
                      }]
                    },
                    "finish_reason": "tool_calls"
                  }]
                }
        - title: App executes and returns the result
          description: >-
            The app runs the function and sends the result back.
            The model incorporates it into its final answer.
          actors_visible: [app, model]
          messages:
            - from: app
              to: model
              label: Tool result
              json_preview: '{"role":"tool","content":"{\"temp\":\"62F\",\"condition\":\"Partly cloudy\"}"}'
              json_full: |
                {
                  "messages": [
                    {"role": "user", "content": "What's the weather in Boston?"},
                    {"role": "assistant", "tool_calls": [{"id": "call_abc123", "type": "function", "function": {"name": "get_weather", "arguments": "{\"location\": \"Boston, MA\"}"}}]},
                    {"role": "tool", "tool_call_id": "call_abc123", "content": "{\"temp\": \"62F\", \"condition\": \"Partly cloudy\", \"humidity\": \"45%\"}"}
                  ]
                }
            - from: model
              to: app
              label: Final answer
              json_preview: '{"content":"It''s 62F and partly cloudy in Boston."}'

  # ── MCP ───────────────────────────────────────────────────────────
  - id: mcp
    title: MCP
    icon_alt: "<>"
    tagline: One protocol for every tool
    detail:
      links:
        - { label: "Launch", url: "https://www.anthropic.com/news/model-context-protocol" }
        - { label: "Spec (2025-03-26)", url: "https://modelcontextprotocol.io/specification/2025-03-26" }
        - { label: "AAIF governance", url: "https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation" }
      what_it_solves: >-
        Now models can call tools — but without MCP, connecting N apps to M tool providers requires N*M
        custom integrations. MCP defines a single client/server protocol
        so any app can discover and use any tool server — just run tools/list to
        find what's available, tools/call to use it, with a standard way to
        authenticate to private servers.
      how_its_standardizing: >-
        Introduced by Anthropic (November 2024). Rapidly adopted across
        the agent tooling ecosystem. Now under open governance through
        the Agentic AI Foundation (AAIF) at the Linux Foundation, with
        community contributions and a growing ecosystem of client and
        server implementations.
      virtuous_cycle:
        - "Tool providers implement one server and reach many MCP clients."
        - "Clients add one protocol and gain access to a growing tool catalog."
        - "Shared conventions reduce integration cost and accelerate new tools."
    animation:
      actors:
        - id: app
          label: Claude
          type: app
        - id: file-server
          label: File Server
          type: server
        - id: db-server
          label: DB Server
          type: server
        - id: cursor
          label: Cursor
          type: app
      scenes:
        - title: Client discovers server tools
          description: >-
            An MCP client connects to a file server and asks what
            tools are available using the standard tools/list method.
          actors_visible: [app, file-server]
          messages:
            - from: app
              to: file-server
              label: tools/list
              json_preview: '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
              json_full: |
                {
                  "jsonrpc": "2.0",
                  "id": 1,
                  "method": "tools/list",
                  "params": {}
                }
            - from: file-server
              to: app
              label: Available tools
              json_preview: '{"result":[{"name":"read_file","description":"Read a file"}]}'
              json_full: |
                {
                  "jsonrpc": "2.0",
                  "id": 1,
                  "result": [{
                    "name": "read_file",
                    "description": "Read a file from the filesystem",
                    "inputSchema": {
                      "type": "object",
                      "properties": {
                        "path": {"type": "string", "description": "File path to read"}
                      },
                      "required": ["path"]
                    }
                  }]
                }
        - title: Client calls a tool
          description: >-
            The client invokes a tool on the server using tools/call.
            The server executes it and returns the result.
          actors_visible: [app, file-server]
          messages:
            - from: app
              to: file-server
              label: tools/call
              json_preview: '{"method":"tools/call","params":{"name":"read_file","arguments":{"path":"README.md"}}}'
              json_full: |
                {
                  "jsonrpc": "2.0",
                  "id": 2,
                  "method": "tools/call",
                  "params": {
                    "name": "read_file",
                    "arguments": {"path": "README.md"}
                  }
                }
            - from: file-server
              to: app
              label: Tool result
              json_preview: '{"result":{"content":[{"type":"text","text":"# My Project..."}]}}'
        - title: Same client, different server
          description: >-
            The same MCP client connects to a database server.
            Same protocol — tools/list, tools/call — different tools.
          actors_visible: [app, db-server]
          sparkle: true
          messages:
            - from: app
              to: db-server
              label: tools/list
              json_preview: '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
            - from: db-server
              to: app
              label: Available tools
              json_preview: '{"result":[{"name":"query","description":"Run a SQL query"}]}'
        - title: Different client, same server
          description: >-
            A completely different app — Cursor — connects to the
            same file server. No changes needed on either side.
          actors_visible: [cursor, file-server]
          sparkle: true
          messages:
            - from: cursor
              to: file-server
              label: tools/list
              json_preview: '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
            - from: file-server
              to: cursor
              label: Same tools
              json_preview: '{"result":[{"name":"read_file","description":"Read a file"}]}'

  # ── MCP Apps ──────────────────────────────────────────────────────
  - id: mcp-apps
    title: MCP Apps
    icon_alt: "UI"
    tagline: Interactive UIs for tool servers
    detail:
      what_it_solves: >-
        MCP makes chatbots the front door to the internet — users might start to make Spotify
        playlists or buy products through their favorite chatbot rather than the original site.
        But some of those interactions might need custom UI that chatbot makers don't want to
        maintain, and some vendors might want to keep a face-to-face relationship with their
        users. MCP Apps provide a safe, controlled way for upstream services to talk 
        directly to the user without leaving their chat.
      how_its_standardizing: >-
        MCP Apps emerged as the convergence point between Anthropic's MCP ecosystem and the demand for rich, safe in-chat UI that OpenAI operationalized with the ChatGPT Apps SDK. OpenAI later documented that ChatGPT implements the MCP Apps UI standard and provides a mapping from Apps SDK patterns to MCP Apps keys, with OpenAI-only extensions as optional add-ons. The MCP community then formalized this as an official extension (modelcontextprotocol/ext-apps), explicitly describing MCP Apps as “inspired by MCP-UI and OpenAI's Apps SDK,” and standardizing the core portability/safety shape: sandboxed iframe rendering plus a host↔app messaging surface.
      virtuous_cycle:
        - "Tool providers can deliver better UX without per-host bespoke UI work."
        - "Hosts gain safer, richer interactions than pure JSON tool results."
        - "A common UI embedding model encourages more reusable tool apps."
      links:
        - label: "OpenAI: Introducing Apps in ChatGPT"
          url: "https://openai.com/index/introducing-apps-in-chatgpt/"
        - label: "OpenAI: MCP Apps in ChatGPT (Apps SDK docs)"
          url: "https://developers.openai.com/apps-sdk/mcp-apps-in-chatgpt/"
        - label: "MCP Docs: Apps Extension"
          url: "https://modelcontextprotocol.io/docs/extensions/apps"
        - label: "MCP Blog: MCP Apps Official Extension (Jan 26, 2026)"
          url: "https://blog.modelcontextprotocol.io/posts/2026-01-26-mcp-apps/"
        - label: "GitHub: modelcontextprotocol/ext-apps"
          url: "https://github.com/modelcontextprotocol/ext-apps"
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: app
        - id: tool
          label: Tool Server
          type: server
        - id: app
          label: MCP App UI
          type: app
      scenes:
        - title: Tool returns a UI surface
          description: >-
            Instead of raw JSON, the tool advertises an interactive UI
            surface that can be embedded by the host.
          actors_visible: [agent, tool]
          messages:
            - from: agent
              to: tool
              label: tools/call
              json_preview: '{"name":"inspect","arguments":{"id":"123"}}'
            - from: tool
              to: agent
              label: app descriptor
              json_preview: '{"type":"app","src":"https://tool/ui/inspect"}'
        - title: Host embeds the UI
          description: >-
            The agent host renders the UI in a sandboxed iframe and
            communicates with it via MCP messaging.
          actors_visible: [agent, app]
          sparkle: true
          messages:
            - from: agent
              to: app
              label: embed
              json_preview: '{"sandbox":true}'

  # ── Standard Tool Surfaces ────────────────────────────────────────
  - id: standard-tool-surfaces
    title: Standard Tools
    icon_alt: "cli"
    tagline: Browser, Command Line, and Code
    detail:
      what_it_solves: >-
        Some tools turn out to be so useful that model makers have to make sure
        during training that they work well, and client apps need standard ways
        to provide them. Three key tools emerge: browser, command line, and code.
      how_its_standardizing: >-
        Convergence happened through training and deployment pressure rather than
        a formal spec. Model cards (e.g., OpenAI's gpt-oss) make explicit that
        models are fine-tuned to operate browser, terminal, and code-editing tools.
        Agent platforms independently settled on similar action vocabularies
        (navigate/click/type; run/exit/stdout; apply_patch/test) because these
        abstractions cover most real-world workflows. The semantics, not the
        wire format, are what standardized.
      virtuous_cycle:
        - "Model developers train on stable tool categories to improve reliability."
        - "Hosts expose consistent tool schemas, enabling cross-model portability."
        - "Evaluation benchmarks align around the same action surfaces, reinforcing convergence."
      links:
        - { label: "OpenAI gpt-oss Model Card (example of tool-specific finetuning)", url: "https://openai.com/research/gpt-oss" }
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: browser
          label: Browser Tool
          type: server
        - id: shell
          label: Command Tool
          type: server
        - id: code
          label: Code Tool
          type: server
      scenes:
        - title: Browser interaction
          description: >-
            The agent navigates a website using a standard browser action
            vocabulary: navigate, click, type.
          actors_visible: [agent, browser]
          messages:
            - from: agent
              to: browser
              label: navigate
              json_preview: '{"url":"https://example.com"}'
              json_full: |
                {
                  "tool": "browser",
                  "action": "navigate",
                  "url": "https://example.com"
                }
            - from: browser
              to: agent
              label: page loaded
              json_preview: '{"title":"Example Domain"}'
              json_full: |
                {
                  "status": "ok",
                  "title": "Example Domain",
                  "url": "https://example.com",
                  "content": "This domain is for use in illustrative examples ..."
                }
        - title: Command execution
          description: >-
            The same agent switches to a shell tool using a familiar
            run/exit/stdout pattern.
          actors_visible: [agent, shell]
          sparkle: true
          messages:
            - from: agent
              to: shell
              label: run
              json_preview: '{"command":"ls"}'
              json_full: |
                {
                  "tool": "shell",
                  "command": "ls",
                  "working_directory": "/home/user/project"
                }
            - from: shell
              to: agent
              label: result
              json_preview: '{"exit_code":0,"stdout":"README.md\nsrc/\ntests/"}'
              json_full: |
                {
                  "exit_code": 0,
                  "stdout": "README.md\nsrc/\ntests/\npackage.json",
                  "stderr": ""
                }
        - title: Code execution
          description: >-
            The agent runs code in a sandboxed interpreter for
            computation, data analysis, or testing logic.
          actors_visible: [agent, code]
          messages:
            - from: agent
              to: code
              label: execute
              json_preview: '{"language":"python","code":"print(2+2)"}'
              json_full: |
                {
                  "tool": "code",
                  "language": "python",
                  "code": "print(2 + 2)"
                }
            - from: code
              to: agent
              label: output
              json_preview: '{"exit_code":0,"stdout":"4"}'
              json_full: |
                {
                  "exit_code": 0,
                  "stdout": "4",
                  "stderr": ""
                }

  # ── Instruction Surfaces ──────────────────────────────────────────
  - id: agents-md
    title: AGENTS.md
    icon_alt: "#"
    tagline: Project-local guidance for agents
    detail:
      links:
        - { label: "Standard", url: "https://agents.md/" }
      what_it_solves: >-
        Now that they can reliably read files and directories, coding agents are
        dropped into unfamiliar repositories and need to know:
        how do I build this? What style conventions matter? What should I
        never touch? Rebuilding this context for each request is inefficient.
        AGENTS.md gives them a predictable, standardized
        place to find project-specific instructions.
      how_its_standardizing: >-
        Community-driven format that emerged from the practice of
        embedding agent instructions in READMEs. Later formalized with a
        public spec and conventions for sections. Reported adoption
        across 60,000+ projects per agents.md tracking.
      virtuous_cycle:
        - "Repo maintainers put instructions in a standard place as they move from tool to tool."
        - "Tool makers start to look in that place to make their tool easier to adopt."
    animation:
      actors:
        - id: agent
          label: Coding Agent
          type: agent
        - id: agent-b
          label: Other Agent
          type: agent
        - id: repo-a
          label: Project Alpha
          type: repo
        - id: repo-b
          label: Project Beta
          type: repo
      scenes:
        - title: Agent opens a repo
          description: >-
            A coding agent is dropped into a repository. It looks for
            AGENTS.md at the project root.
          actors_visible: [agent, repo-a]
          messages:
            - from: agent
              to: repo-a
              label: Read AGENTS.md
              json_preview: 'GET /AGENTS.md'
            - from: repo-a
              to: agent
              label: Project instructions
              json_preview: '## Setup\n- `uv sync && uv run pytest`\n## Style\n- Run ruff format'
              json_full: |
                # AGENTS.md

                ## Setup
                - `uv sync`
                - `uv run pytest`

                ## How to work
                - Prefer small PRs.
                - Run `ruff format` before commit.

                ## Boundaries
                - Never change prod credentials handling without a reviewer.
        - title: Agent follows the instructions
          description: >-
            The agent reads the setup, style, and boundary sections,
            then works within those constraints automatically.
          actors_visible: [agent, repo-a]
          messages:
            - from: agent
              to: repo-a
              label: Runs setup
              json_preview: '$ uv sync && uv run pytest'
            - from: agent
              to: repo-a
              label: Follows style
              json_preview: '$ ruff format src/'
        - title: Different repo, same convention
          description: >-
            The agent moves to a completely different project. It finds
            another AGENTS.md and adapts immediately — no reconfiguration.
          actors_visible: [agent, repo-b]
          sparkle: true
          messages:
            - from: agent
              to: repo-b
              label: Read AGENTS.md
              json_preview: 'GET /AGENTS.md'
            - from: repo-b
              to: agent
              label: Different instructions
              json_preview: '## Setup\n- `npm install && npm test`\n## Style\n- Use TypeScript strict'
        - title: Different agent, same repo
          description: >-
            A completely different coding agent opens the same project.
            Same AGENTS.md, same instructions — write once, any agent reads.
          actors_visible: [agent-b, repo-a]
          sparkle: true
          messages:
            - from: agent-b
              to: repo-a
              label: Read AGENTS.md
              json_preview: 'GET /AGENTS.md'
            - from: repo-a
              to: agent-b
              label: Same instructions
              json_preview: '## Setup\n- `uv sync && uv run pytest`\n## Style\n- Run ruff format'

  - id: llms-txt
    title: llms.txt
    icon_alt: "//"
    tagline: AI-readable site index
    detail:
      links:
        - { label: "Standard", url: "https://llmstxt.org/" }
      what_it_solves: >-
        Model knowledge is frozen when the model is trained, but an agent might need more recent information,
        such as the documentation for a software library that hadn't been released yet when the model was trained.
        Agents can use web browsers to fetch that information, but browsing around for the right pages, fetching
        web pages designed for humans,
        and then extracting the information they need, is inefficient both for the agents and for the websites.
        llms.txt is a simple Markdown index at a well-known URL that
        tells agents where to look for key information designed for them to read.
      how_its_standardizing: >-
        Proposed by Jeremy Howard (September 2024). Adopted by
        documentation platforms and developer tools, with growing
        ecosystem support for auto-generating llms.txt files from
        existing site content.
      virtuous_cycle:
        - "Agents that know to use llms.txt spend fewer tokens and fetch fewer pages for more accurate information."
        - "Websites for services that want to be used by agents add llms.txt to encourage their use."
        - "Tools for publishing documentation add automatic generators; adoption becomes near-zero effort."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: site-a
          label: docs.example.com
          type: website
        - id: site-b
          label: api.other.dev
          type: website
      scenes:
        - title: Agent needs documentation
          description: >-
            An agent needs to understand an API. Instead of crawling
            the whole site, it fetches /llms.txt for a curated index.
          actors_visible: [agent, site-a]
          messages:
            - from: agent
              to: site-a
              label: Fetch /llms.txt
              json_preview: 'GET /llms.txt'
            - from: site-a
              to: agent
              label: Structured index
              json_preview: '# docs.example.com\n## Docs\n- /docs/getting-started\n- /docs/api'
              json_full: |
                # docs.example.com

                ## Docs
                - /docs/getting-started
                - /docs/api

                ## Canonical specs
                - /docs/protocol
                - /docs/security

                ## Examples
                - /docs/examples/basic
        - title: Agent fetches exactly what it needs
          description: >-
            With the index, the agent knows precisely which pages to
            read — no wasted tokens on irrelevant content.
          actors_visible: [agent, site-a]
          messages:
            - from: agent
              to: site-a
              label: Fetch specific page
              json_preview: 'GET /docs/api'
            - from: site-a
              to: agent
              label: Focused content
              json_preview: '# API Reference\n## Authentication\nUse Bearer tokens...'
        - title: Works on any site
          description: >-
            A different website also publishes llms.txt. The agent
            uses the same approach — one convention, every site.
          actors_visible: [agent, site-b]
          sparkle: true
          messages:
            - from: agent
              to: site-b
              label: Fetch /llms.txt
              json_preview: 'GET /llms.txt'
            - from: site-b
              to: agent
              label: Structured index
              json_preview: '# api.other.dev\n## Endpoints\n- /reference/auth\n- /reference/users'

  - id: agent-skills
    title: Agent Skills
    icon_alt: "pkg"
    tagline: Portable capability packages
    detail:
      links:
        - { label: "Standard", url: "https://agentskills.io/specification" }
        - { label: "Codex skills docs", url: "https://developers.openai.com/codex/skills/" }
      what_it_solves: >-
        As agents grew beyond a handful of tools, two problems emerged:
        (1) reliability and consistency: teams and communities wanted to share and improve
        increasingly long and specific prompts to handle particular situations; and
        (2) scale: agents need dozens or hundreds of reusable procedures,
        scripts, and references without bloating every run's context. Agent skills package
        task-specific playbooks (and optional scripts/resources) so an agent framework can load
        just the metadata up front, then pull full instructions and files only when the
        task calls for them.
      how_its_standardizing: >-
        The format was developed in the Anthropic ecosystem (notably Claude Code) and
        released as an open standard. OpenAI's Codex
        built on the open Agent Skills standard,
        and vendors published cross-agent skill repos (e.g., Cloudflare). Agent frameworks are converging on common local install locations and emerging “well-known” publishing patterns.
      virtuous_cycle:
        - "Users working within a particular agent ecosystem develop a way to share skills with each other."
        - "Builders of other agent ecosystems add support for the same format to benefit from the shared skills."
        - "Users benefit from sharing skills across ecosystems."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: site-a
          label: docs.example.com
          type: website
        - id: site-b
          label: api.other.dev
          type: website
      scenes:
        - title: Host discovers installed skills (metadata only)
          description: >-
            At startup, hosts scan a known local skills directory and load only the
            SKILL.md frontmatter (name + description) for every skill.
          actors_visible: [host, skills-dir]
          messages:
            - from: host
              to: skills-dir
              label: Scan skills directory
              json_preview: 'list ~/.config/agent/skills/*/SKILL.md'
            - from: skills-dir
              to: host
              label: Read frontmatter only
              json_preview: '[{"name":"weather","description":"Look up current weather"}]'
              json_full: |
                ~/.config/agent/skills/
                  weather/
                    SKILL.md
                    scripts/get_weather.py
                    references/open-meteo.md

                ---
                name: weather
                description: Look up current weather for a location.
                ---

        - title: Host activates a skill (load instructions on demand)
          description: >-
            When a task matches, the host loads the full SKILL.md instructions and
            any referenced files as needed (scripts, references).
          actors_visible: [host, skill]
          messages:
            - from: host
              to: skill
              label: Load SKILL.md body
              json_preview: 'Read skills/weather/SKILL.md (full)'
              json_full: |
                ---
                name: weather
                description: Look up current weather for a location.
                ---

                ## Inputs
                - location (string)

                ## Output
                - JSON: { "temp_c": number, "summary": string }

                ## Steps
                1. Run scripts/get_weather.py with the location.
                2. If API errors occur, consult references/open-meteo.md.

            - from: host
              to: skill
              label: Run skill script
              json_preview: '$ python scripts/get_weather.py --location "Boston, MA"'

        - title: Same skill works in different agent products
          description: >-
            Because the directory + SKILL.md contract is shared, different hosts can
            install the same skill bundle without rewriting it.
          actors_visible: [skill, host]
          sparkle: true
          messages:
            - from: host
              to: skill
              label: Install skill bundle
              json_preview: 'install cloudflare/skills (Agent Skills format)'
            - from: skill
              to: host
              label: Ready
              json_preview: 'discovered: name="weather"'

  - id: agent-skills-discovery
    title: Agent Skills Discovery
    icon_alt: "compass"
    tagline: Find skills published by a trusted website
    detail:
      links:
        - { label: "Cloudflare: Agent Skills Discovery RFC", url: "https://github.com/cloudflare/agent-skills-discovery-rfc" }
        - { label: "Mintlify: Skills discovery from any URL", url: "https://www.mintlify.com/blog/skills-discovery-from-any-url" }
        - { label: "RFC 8615 (.well-known)", url: "https://www.rfc-editor.org/rfc/rfc8615" }
      what_it_solves: >-
        The Agent Skills format standardizes a skill bundle on disk, but it doesn't
        answer: “given a docs or product URL, where are the skills for this thing?”
        Skills Discovery adds an llms.txt-like discovery mechanism: a predictable
        well-known index that lists the skills published by that site or docs root.
      how_its_standardizing: >-
        Cloudflare's RFC proposes serving a JSON index under `/.well-known/skills/`
        (built on RFC 8615). Tooling has started to implement it in practice: e.g.,
        Mintlify auto-serves the index for docs sites and a CLI can install skills
        from a URL without knowing repository structure.
      virtuous_cycle:
        - "Sites publish a predictable index; agents fetch fewer pages and waste fewer tokens."
        - "CLIs/hosts can 'add skill from URL' with one convention instead of bespoke scraping."
        - "More publishers adopt it because it becomes the default way agents learn products."
    animation:
      actors:
        - id: agent
          label: Agent Host / CLI
          type: agent
        - id: site
          label: docs.example.com
          type: website
        - id: skills
          label: Local Skills Folder
          type: repo
      scenes:
        - title: Fetch the well-known skills index
          description: >-
            The host is given a docs URL and looks for a predictable index under
            `/.well-known/skills/` to learn what skills exist for that site.
          actors_visible: [agent, site]
          messages:
            - from: agent
              to: site
              label: GET index.json
              json_preview: 'GET /docs/.well-known/skills/index.json'
            - from: site
              to: agent
              label: Available skills
              json_preview: '{"skills":[{"name":"payments","description":"Integrate checkout","files":["SKILL.md"]}]}'
        - title: Install to the local skills directory
          description: >-
            The host downloads the listed files and installs the bundle into the
            standard local skills location for immediate use.
          actors_visible: [agent, skills]
          sparkle: true
          messages:
            - from: agent
              to: site
              label: Fetch SKILL.md
              json_preview: 'GET /docs/.well-known/skills/payments/SKILL.md'
            - from: agent
              to: skills
              label: Write local skill bundle
              json_preview: 'write ~/.config/agent/skills/payments/SKILL.md'


  - id: agent-skills-registries
    title: Agent Skills Registries
    icon_alt: "dir"
    tagline: npm-style catalogs for skills
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Solo.io: agentregistry launch", url: "https://www.solo.io/press-releases/agent-skills-kubernetes-ecosystem" }
        - { label: "Solo.io Lab: Introduction to agentregistry", url: "https://www.solo.io/resources/lab/introduction-to-agentregistry" }
        - { label: "Agent Skills spec (package format)", url: "https://agentskills.io/specification" }
      what_it_solves: >-
        As agent skills proliferate, users will want to find popular and well supported skills for specific tasks
        ("what are the best skills for checking website accessibility?"). And as agents become more self-sufficient,
        users may want them to go out and discover their own high quality skills as needed, rather than be limited to skills predicted by the agent's developer.
        Skills registries would enable search, versions, metadata, curation, and organization-wide distribution,
        similar to package managers for software libraries like npm or PyPI. This (we can hope!) also becomes the natural home for provenance, permissions, and policy metadata.
      how_its_standardizing: >-
        Registry behavior is emerging via vendor/open-source projects (e.g., Solo.io's
        agentregistry or ClawHub.ai) that store skills and MCP servers with metadata, pull/install
        workflows, and enterprise distribution patterns. A shared registry protocol
        is not yet settled; convergence pressure will likely focus on a common
        "package + manifest + fetch" surface layered on the Agent Skills bundle format.
      virtuous_cycle:
        - "Publishers ship one artifact; many hosts can search and install it."
        - "Organizations centralize distribution and policy instead of copying files around."
        - "Security metadata (signing, permissions, sandbox expectations, trust relationships) enables use by more cautious users."
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: agent
        - id: registry
          label: Skills Registry
          type: registry
        - id: skills
          label: Local Skills Folder
          type: repo
      scenes:
        - title: Search the registry for a skill
          description: >-
            The host queries a registry by task/keyword and gets back candidate skills
            with versions and basic metadata.
          actors_visible: [agent, registry]
          messages:
            - from: agent
              to: registry
              label: search
              json_preview: '{"q":"checkout integration","limit":5}'
            - from: registry
              to: agent
              label: results
              json_preview: '[{"name":"payments","version":"1.2.0","summary":"Integrate checkout flows"}]'
        - title: Pull and install (policy to be worked out)
          description: >-
            The host downloads the selected skill bundle and installs it locally.
            Registries are the natural place to attach provenance/permissions later.
          actors_visible: [agent, registry, skills]
          sparkle: true
          messages:
            - from: agent
              to: registry
              label: pull
              json_preview: '{"name":"payments","version":"1.2.0"}'
            - from: registry
              to: agent
              label: bundle + manifest
              json_preview: '{"files":["SKILL.md","scripts/checkout.py"],"manifest":"..."}'
            - from: agent
              to: skills
              label: install
              json_preview: 'write ~/.config/agent/skills/payments/...'

  # ── Agent Loop ──────────────────────────────────────────────────────
  - id: agent-loop
    title: Agent Loop
    icon_alt: "loop"
    tagline: Models that keep going
    detail:
      links:
        - { label: "Pattern", url: "https://www.anthropic.com/engineering/building-effective-agents" }
        - { label: "goose (described as a 'reference implementation' contributed to the Linux Foundation)", url: "https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation" }
      what_it_solves: >-
        Tool calling lets a model request one action — but real tasks require
        many steps. The agent loop is the pattern of repeatedly calling the
        model, executing its tool requests, feeding results back, and continuing
        until the model signals completion. This loop turns a chat model into
        an autonomous agent.
      how_its_standardizing: >-
        De facto convergence across agent frameworks (LangChain, AutoGPT,
        Claude computer use, OpenAI Assistants). The pattern is consistent:
        system prompt + user goal, model responds with tool calls or final
        answer, host executes and re-prompts. No formal spec, but the shape
        is universal.
      virtuous_cycle:
        - "Developers build on the pattern rather than inventing custom control flows."
        - "Models are trained to emit stop signals and multi-step plans reliably."
        - "Tooling (tracing, guardrails, timeouts) targets a predictable execution model."
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: agent
        - id: model
          label: Model
          type: model
        - id: tool
          label: Tool
          type: server
      scenes:
        - title: Plan
          description: >-
            The agent asks the model what to do next given the current state.
          actors_visible: [agent, model]
          messages:
            - from: agent
              to: model
              label: prompt
              json_preview: '{"goal":"Fix failing tests"}'
        - title: Act
          description: >-
            The model emits a tool call; the host executes it.
          actors_visible: [agent, model, tool]
          messages:
            - from: model
              to: agent
              label: tool_call
              json_preview: '{"name":"run_tests"}'
            - from: agent
              to: tool
              label: execute
              json_preview: '{"cmd":"pytest"}'
        - title: Iterate
          description: >-
            Results are fed back into the model, continuing the loop
            until completion.
          actors_visible: [agent, model]
          sparkle: true
          messages:
            - from: agent
              to: model
              label: result
              json_preview: '{"failures":0}'

  # ── AgentCard ───────────────────────────────────────────────────────
  - id: agent-card
    title: AgentCard
    icon_alt: "card"
    tagline: Well-known agent descriptors
    detail:
      links:
        - { label: "A2A AgentCard spec", url: "https://agent2agent.info/specification/#agentcard" }
      what_it_solves: >-
        Before agents can collaborate, they need to discover each other's
        capabilities, endpoints, and authentication requirements. AgentCard
        is a JSON descriptor at a well-known URL that tells other agents
        what this agent can do and how to talk to it.
      how_its_standardizing: >-
        Defined as part of A2A. Agents publish a JSON file at
        /.well-known/agent-card.json describing name, skills, supported
        input/output modes, and auth schemes. Provides the discovery
        primitive that higher-level registries can index.
      virtuous_cycle:
        - "Agents can discover each other without a central directory."
        - "Registries index the same descriptor format across vendors."
        - "A standard metadata shape enables tooling (routers, monitors, catalogs)."
    animation:
      actors:
        - id: client
          label: Client Agent
          type: agent
        - id: remote
          label: InvoiceAgent (Remote)
          type: agent
        - id: registry
          label: Agent Registry / Router
          type: registry

      scenes:
        - title: Fetch AgentCard (bootstrap)
          description: >-
            The client discovers the remote agent by fetching a well-known
            descriptor. This is metadata only: no task is submitted yet.
          actors_visible: [client, remote]
          messages:
            - from: client
              to: remote
              label: GET /.well-known/agent-card.json
              json_preview: 'GET /.well-known/agent-card.json'
              json_full: |
                GET /.well-known/agent-card.json HTTP/1.1
                Host: agent.example
                Accept: application/json
            - from: remote
              to: client
              label: AgentCard
              json_preview: '{"name":"InvoiceAgent","url":"https://agent.example/a2a","authentication":{"schemes":["Bearer","mTLS"]},"defaultInputModes":["application/pdf"],"skills":[{"id":"extract"}]}'
              json_full: |
                {
                  "name": "InvoiceAgent",
                  "description": "Extracts invoice fields from PDFs",
                  "url": "https://agent.example/a2a",
                  "provider": { "organization": "ExampleCo", "url": "https://example.com" },
                  "version": "1.0.0",
                  "capabilities": {
                    "streaming": true,
                    "pushNotifications": false,
                    "stateTransitionHistory": true
                  },
                  "authentication": { "schemes": ["Bearer", "mTLS"] },
                  "defaultInputModes": ["application/pdf", "text/plain"],
                  "defaultOutputModes": ["application/json"],
                  "skills": [{
                    "id": "extract",
                    "name": "Extract invoice",
                    "description": "Parse invoice fields from documents",
                    "tags": ["ap", "invoice"],
                    "examples": ["Extract totals from this PDF"]
                  }]
                }

        - title: Preflight compatibility + auth negotiation
          description: >-
            The client uses AgentCard to decide whether delegation makes sense:
            required skill exists, I/O modes match, and an auth scheme can be chosen.
          actors_visible: [client, remote]
          sparkle: true
          messages:
            - from: client
              to: client
              label: Select skill + mode
              json_preview: 'need: skill="extract" input="application/pdf" output="application/json"'
              json_full: |
                Preflight checks:
                - Has skill "extract"? ✅
                - Accepts input mode "application/pdf"? ✅
                - Produces "application/json"? ✅
            - from: client
              to: client
              label: Choose authentication scheme
              json_preview: 'auth: pick "Bearer" (token available)'
              json_full: |
                Authentication negotiation:
                - Supported schemes: Bearer, mTLS
                - Available creds: Bearer token
                - Selected: Bearer

        - title: Registry indexes AgentCards (directory without lock-in)
          description: >-
            A registry/router can index many AgentCards to enable search and routing,
            while the source of truth remains each agent's well-known descriptor.
          actors_visible: [registry, remote]
          sparkle: true
          messages:
            - from: registry
              to: remote
              label: Crawl AgentCard
              json_preview: 'GET /.well-known/agent-card.json'
            - from: remote
              to: registry
              label: AgentCard metadata
              json_preview: '{"name":"InvoiceAgent","skills":[{"id":"extract","tags":["invoice"]}],"url":"https://agent.example/a2a"}'
            - from: registry
              to: registry
              label: Index for routing
              json_preview: 'index += {"skill":"extract","agent":"InvoiceAgent","endpoint":"https://agent.example/a2a"}'
              json_full: |
                Registry index entry:
                {
                  "skill": "extract",
                  "agent": "InvoiceAgent",
                  "endpoint": "https://agent.example/a2a",
                  "auth": ["Bearer", "mTLS"],
                  "modes": { "in": ["application/pdf"], "out": ["application/json"] }
                }


  # ── A2A ───────────────────────────────────────────────────────────
  - id: a2a
    title: A2A
    icon_alt: "<>"
    tagline: Agents working across frameworks
    detail:
      links:
        - { label: "Launch", url: "https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/" }
        - { label: "Specification", url: "https://agent2agent.info/specification/" }
        - { label: "Linux Foundation", url: "https://www.linuxfoundation.org/projects/agent2agent" }
      what_it_solves: >-
        Agents built on different frameworks — by different vendors — need
        to discover each other, negotiate capabilities, and coordinate on
        tasks. A2A provides a standard protocol for agent-to-agent
        interoperability without requiring shared internals.
      how_its_standardizing: >-
        Announced by Google (April 2025). Quickly moved to open
        governance under the Linux Foundation. Implemented by multiple
        platforms; Microsoft ecosystem documentation positions it as a
        standard integration surface.
      virtuous_cycle:
        - "Enterprises can compose agents across vendors instead of buying a monolith."
        - "Vendors become more valuable by being interoperable, not isolated."
        - "A shared task/artifact model enables tooling (routers, registries, monitors)."
    animation:
      actors:
        - id: client
          label: Client Agent
          type: agent
        - id: invoice
          label: InvoiceAgent (Remote)
          type: agent
        - id: artifact
          label: Artifact Store
          type: server

      scenes:
        - title: Create task (lifecycle begins)
          description: >-
            After AgentCard preflight (skill/mode/auth), the client submits an A2A task.
            The remote agent acknowledges with a task id and enters a working state.
          actors_visible: [client, invoice]
          messages:
            - from: client
              to: invoice
              label: Submit task
              json_preview: '{"task":{"id":"t-123","state":"submitted"},"messages":[{"role":"user","parts":[{"content_type":"text/plain","content":"Extract invoice fields from this PDF."}]}]}'
              json_full: |
                POST /tasks HTTP/1.1
                Host: agent.example
                Authorization: Bearer $TOKEN
                Content-Type: application/json

                {
                  "task": { "id": "t-123", "state": "submitted" },
                  "messages": [{
                    "role": "user",
                    "parts": [{
                      "content_type": "text/plain",
                      "content": "Extract invoice fields from this PDF."
                    }, {
                      "content_type": "application/pdf",
                      "uri": "https://example.com/inv.pdf"
                    }]
                  }]
                }
            - from: invoice
              to: client
              label: Accepted (working)
              json_preview: '{"task":{"id":"t-123","state":"working"},"status":"accepted"}'
              json_full: |
                {
                  "task": { "id": "t-123", "state": "working" },
                  "status": "accepted"
                }

        - title: Stream progress updates
          description: >-
            Long tasks benefit from streaming: the remote agent emits incremental updates
            (progress, intermediate messages, or partial outputs) until completion.
          actors_visible: [client, invoice]
          sparkle: true
          messages:
            - from: invoice
              to: client
              label: Progress update
              json_preview: '{"task":{"id":"t-123","state":"working"},"progress":0.35,"message":{"role":"assistant","parts":[{"content_type":"text/plain","content":"Found totals + vendor header. Parsing line items next."}]}}'
            - from: invoice
              to: client
              label: Progress update
              json_preview: '{"task":{"id":"t-123","state":"working"},"progress":0.75,"message":{"role":"assistant","parts":[{"content_type":"text/plain","content":"Line items parsed; normalizing dates/currency."}]}}'

        - title: Deliver artifacts by reference
          description: >-
            The remote agent completes the task and returns artifacts. Artifacts are
            often referenced by URI so large outputs don’t bloat messages.
          actors_visible: [client, invoice, artifact]
          messages:
            - from: invoice
              to: artifact
              label: Store output artifact
              json_preview: 'PUT /artifacts/t-123/extracted.json'
            - from: invoice
              to: client
              label: Completed + artifact references
              json_preview: '{"task":{"id":"t-123","state":"completed"},"artifacts":[{"name":"extracted.json","content_type":"application/json","uri":"https://agent.example/artifacts/t-123/extracted.json"}]}'
              json_full: |
                {
                  "task": { "id": "t-123", "state": "completed" },
                  "artifacts": [{
                    "name": "extracted.json",
                    "content_type": "application/json",
                    "uri": "https://agent.example/artifacts/t-123/extracted.json"
                  }]
                }
            - from: client
              to: artifact
              label: Fetch artifact
              json_preview: 'GET /artifacts/t-123/extracted.json'
            - from: artifact
              to: client
              label: extracted.json
              json_preview: '{"vendor":"ExampleCo","invoice_number":"INV-1042","total":{"amount":123.45,"currency":"USD"}}'
              json_full: |
                {
                  "vendor": "ExampleCo",
                  "invoice_number": "INV-1042",
                  "date": "2026-02-01",
                  "total": { "amount": 123.45, "currency": "USD" },
                  "line_items": [
                    { "description": "Consulting", "qty": 2, "unit_price": 50.00, "amount": 100.00 },
                    { "description": "Tax", "qty": 1, "unit_price": 23.45, "amount": 23.45 }
                  ]
                }

        - title: Cancel an in-flight task (control plane)
          description: >-
            A2A includes control-plane operations like cancellation for safety, cost,
            and user control in multi-step workflows.
          actors_visible: [client, invoice]
          sparkle: true
          messages:
            - from: client
              to: invoice
              label: Cancel task
              json_preview: 'POST /tasks/t-123/cancel'
              json_full: |
                POST /tasks/t-123/cancel HTTP/1.1
                Host: agent.example
                Authorization: Bearer $TOKEN
            - from: invoice
              to: client
              label: Canceled
              json_preview: '{"task":{"id":"t-123","state":"canceled"},"status":"ok"}'
              json_full: |
                {
                  "task": { "id": "t-123", "state": "canceled" },
                  "status": "ok"
                }

  # ── Domain Protocols ──────────────────────────────────────────────
  - id: ucp
    title: UCP
    badge: unclear_adoption
    icon_alt: "$"
    tagline: Universal agent commerce
    detail:
      links:
        - { label: "Shopify launch", url: "https://www.shopify.com/ucp" }
        - { label: "Google explainer", url: "https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/" }
      what_it_solves: >-
        Agents that shop need a standard way to browse products, build
        carts, and complete checkout across different merchants — without
        custom integration per store. UCP defines capabilities discovery,
        checkout sessions, and payment handlers for agent commerce.
      how_its_standardizing: >-
        Launched January 2026 by Shopify and Google. Specifies capability
        negotiation, checkout session creation, and payment handler
        interfaces. Supported by large retailers and payments ecosystem
        partners. Open for any merchant, agent, or payment processor.
      virtuous_cycle:
        - "Merchants implement once and accept many agents."
        - "Agents implement once and can shop broadly."
    animation:
      actors:
        - id: agent
          label: Shopping Agent
          type: agent
        - id: merchant-a
          label: Flower Shop
          type: merchant
        - id: merchant-b
          label: Book Store
          type: merchant
      scenes:
        - title: Agent creates a checkout
          description: >-
            The shopping agent creates a checkout session with a
            merchant, sending line items and buyer info.
          actors_visible: [agent, merchant-a]
          messages:
            - from: agent
              to: merchant-a
              label: Create checkout session
              json_preview: '{"line_items":[{"item":{"id":"bouquet_roses"},"quantity":1}],"currency":"USD"}'
              json_full: |
                POST /checkout-sessions
                UCP-Agent: profile="https://agent.example/profile"
                {
                  "line_items": [{
                    "item": {"id": "bouquet_roses", "title": "Red Rose Bouquet"},
                    "quantity": 1
                  }],
                  "buyer": {
                    "full_name": "John Doe",
                    "email": "john.doe@example.com"
                  },
                  "currency": "USD",
                  "payment": {
                    "instruments": [],
                    "handlers": [{
                      "id": "shop_pay",
                      "name": "com.shopify.shop_pay",
                      "version": "2026-01-11"
                    }]
                  }
                }
            - from: merchant-a
              to: agent
              label: Session ready
              json_preview: '{"id":"session-abc","status":"ready_for_complete","total":"$49.99"}'
              json_full: |
                {
                  "ucp": {
                    "version": "2026-01-11",
                    "capabilities": [{
                      "name": "dev.ucp.shopping.checkout",
                      "version": "2026-01-11"
                    }]
                  },
                  "id": "session-abc",
                  "status": "ready_for_complete",
                  "total": {"amount": 4999, "currency": "USD"}
                }
        - title: Agent completes purchase
          description: >-
            The agent confirms the purchase. The merchant processes
            payment and returns an order confirmation.
          actors_visible: [agent, merchant-a]
          messages:
            - from: agent
              to: merchant-a
              label: Complete checkout
              json_preview: '{"session_id":"session-abc","action":"complete"}'
            - from: merchant-a
              to: agent
              label: Order confirmed
              json_preview: '{"order_id":"ord-789","status":"confirmed"}'
        - title: Same protocol, different merchant
          description: >-
            The agent shops at a completely different store. Same
            checkout flow, same API shape — no new integration needed.
          actors_visible: [agent, merchant-b]
          sparkle: true
          messages:
            - from: agent
              to: merchant-b
              label: Create checkout session
              json_preview: '{"line_items":[{"item":{"id":"novel_123"},"quantity":2}],"currency":"USD"}'
            - from: merchant-b
              to: agent
              label: Session ready
              json_preview: '{"id":"session-xyz","status":"ready_for_complete","total":"$31.98"}'

  - id: web-bot-auth
    title: Web Bot Auth
    icon_alt: "wba"
    badge: unclear_adoption
    tagline: Cryptographic identity for automated web traffic
    detail:
      links:
        - { label: "Cloudflare: Web Bot Auth docs", url: "https://developers.cloudflare.com/bots/reference/bot-verification/web-bot-auth/" }
        - { label: "IETF WG: webbotauth", url: "https://datatracker.ietf.org/wg/webbotauth/" }
        - { label: "IETF draft: architecture", url: "https://datatracker.ietf.org/doc/draft-meunier-web-bot-auth-architecture/" }
        - { label: "Cloudflare blog: signed agents", url: "https://blog.cloudflare.com/signed-agents/" }
      what_it_solves: >-
        Websites struggle to distinguish legitimate automated clients (bots and AI agents)
        from spoofed traffic using brittle signals like IP allowlists and User-Agent strings.
        Web Bot Auth provides a way for automated clients to present a verifiable identity
        by signing HTTP requests, so web services that want to serve some bots but not
        others can do so reliably.
      how_its_standardizing: >-
        Web Bot Auth is emerging via two coupled tracks:
        (1) operational deployment (e.g., CDNs verifying signed bot/agent requests and
        maintaining directories of recognized entities), and
        (2) an IETF working group (webbotauth) drafting interoperable architecture and
        registry conventions. In practice, adoption pressure comes from bot mitigation
        economics: “friendly automation” needs an authentication mechanism that scales
        across many origins without per-site bespoke integration.
      virtuous_cycle:
        - "Still uncertain — there may be a chicken and egg problem."
        - "Bot authors adopt authentication to use key hosted services."
        - "Other services can adopt authentication once supported by major agent frameworks."
    animation:
      actors:
        - id: agent
          label: Signed Agent
          type: agent
        - id: cdn
          label: CDN / Bot Manager
          type: server
        - id: origin
          label: Origin Site
          type: website
        - id: directory
          label: Signature Directory
          type: registry
      scenes:
        - title: Publish a verifiable identity (directory)
          description: >-
            The operator publishes metadata and a public key in a directory so verifiers can
            fetch the key material needed to validate request signatures.
          actors_visible: [agent, directory]
          messages:
            - from: agent
              to: directory
              label: Publish agent key metadata
              json_preview: 'PUT /directory/agents/acme-shopping-agent'
              json_full: |
                PUT /directory/agents/acme-shopping-agent HTTP/1.1
                Content-Type: application/json

                {
                  "name": "Acme Shopping Agent",
                  "issuer": "Acme, Inc.",
                  "keys": [{
                    "kid": "acme-key-1",
                    "alg": "Ed25519",
                    "public_key": "BASE64..."
                  }],
                  "contact": "security@acme.example",
                  "policy": "https://acme.example/agent-policy"
                }

        - title: Sign outbound requests (agent → web)
          description: >-
            The agent signs selected HTTP request components so the verifier can confirm
            integrity and bind the request to the agent identity.
          actors_visible: [agent, cdn, origin]
          messages:
            - from: agent
              to: cdn
              label: Signed request
              json_preview: 'Signature-Input: sig=("@method" "@path" "host")...; Signature: sig=:...:'
              json_full: |
                GET /search?q=running+shoes HTTP/1.1
                Host: shop.example
                Signature-Input: sig=("@method" "@path" "host");created=1735689600;
                  keyid="acme-key-1";alg="ed25519";nonce="8b4a..."
                Signature: sig=:BASE64_SIGNATURE:

        - title: Verify at the edge (CDN)
          description: >-
            The CDN verifies the signature by retrieving the public key and reconstructing
            the signature base. Verified identity can drive allow/deny/rate-limit policy.
          actors_visible: [cdn, directory, origin]
          sparkle: true
          messages:
            - from: cdn
              to: directory
              label: Fetch public key
              json_preview: 'GET /directory/agents/acme-shopping-agent#kid=acme-key-1'
            - from: directory
              to: cdn
              label: Key material
              json_preview: '{"kid":"acme-key-1","alg":"Ed25519","public_key":"BASE64..."}'
            - from: cdn
              to: cdn
              label: Validate signature
              json_preview: 'verify(sig_base, signature, public_key) -> true'
            - from: cdn
              to: origin
              label: Forward with verified identity
              json_preview: 'X-Agent-Verified: acme-shopping-agent'

        - title: Fallback behavior (not enrolled / invalid signature)
          description: >-
            If verification fails, the request is treated as ordinary automated traffic
            and may be challenged, throttled, or blocked based on site policy.
          actors_visible: [cdn, origin]
          messages:
            - from: cdn
              to: origin
              label: Unverified automation path
              json_preview: 'X-Agent-Verified: false; action=rate_limit'


  - id: visa-tap
    title: Visa TAP
    icon_alt: "tap"
    badge: unclear_adoption
    tagline: Merchant verification of credentialed agents
    detail:
      links:
        - { label: "Visa Developer: TAP overview", url: "https://developer.visa.com/capabilities/trusted-agent-protocol" }
        - { label: "Visa Developer: TAP specifications", url: "https://developer.visa.com/capabilities/trusted-agent-protocol/trusted-agent-protocol-specifications" }
        - { label: "GitHub: visa/trusted-agent-protocol", url: "https://github.com/visa/trusted-agent-protocol" }
        - { label: "Visa newsroom: TAP announcement", url: "https://investor.visa.com/news/news-details/2025/Visa-Introduces-Trusted-Agent-Protocol-An-Ecosystem-Led-Framework-for-AI-Commerce/default.aspx" }
      what_it_solves: >-
        Merchants need to reliably distinguish credentialed shopping agents acting on behalf
        of users from anonymous automation, while minimizing changes to existing web checkout
        flows. TAP standardizes the core merchant-side tasks: retrieving an agent's public key,
        verifying a signed request, and applying consistent handling and controls for
        agent-initiated commerce interactions.
      how_its_standardizing: >-
        TAP is industry-led: Visa published specifications and reference implementations,
        and positions the protocol as compatible with existing web infrastructure and aligned
        with broader “signed agent” approaches. Standardization pressure comes from
        payment-adjacent incentives (fraud reduction, merchant trust, predictable onboarding)
        and from reusable reference components (agent registry, verification proxy patterns).
      virtuous_cycle:
        - "Agents onboard once and gain broader merchant acceptance."
        - "Merchants implement one verification flow and safely accept multiple agents."
    animation:
      actors:
        - id: agent
          label: Trusted Agent
          type: agent
        - id: proxy
          label: Verification Proxy (Edge/CDN)
          type: server
        - id: merchant
          label: Merchant Site
          type: merchant
        - id: registry
          label: Agent Registry
          type: registry
      scenes:
        - title: Agent signs a commerce request
          description: >-
            The agent includes a recognition signature in requests to the merchant,
            enabling verification of integrity and agent identity.
          actors_visible: [agent, proxy, merchant]
          messages:
            - from: agent
              to: proxy
              label: Signed request (agent recognition)
              json_preview: 'Signature-Input: sig=("@method" "@path" "host")...; keyid="agent-key-123"'
              json_full: |
                POST /checkout HTTP/1.1
                Host: merchant.example
                Content-Type: application/json
                Signature-Input: sig=("@method" "@path" "host" "content-digest");created=1735689600;
                  keyid="agent-key-123";alg="ed25519";nonce="c91e..."
                Signature: sig=:BASE64_SIGNATURE:

                { "cart_id": "c-77", "shipping": { "zip": "02138" } }

        - title: Merchant retrieves the agent public key
          description: >-
            To validate the signature, the verifier fetches the public key corresponding to keyid.
          actors_visible: [proxy, registry]
          messages:
            - from: proxy
              to: registry
              label: Lookup key by keyid
              json_preview: 'GET /agents/keys/agent-key-123'
            - from: registry
              to: proxy
              label: Public key + metadata
              json_preview: '{"keyid":"agent-key-123","alg":"Ed25519","public_key":"BASE64...","agent":"InvoiceAgent"}'

        - title: Verify and forward to merchant backend
          description: >-
            The verifier reconstructs the signature base from the received request,
            verifies the signature, then forwards the request with verified identity context.
          actors_visible: [proxy, merchant]
          sparkle: true
          messages:
            - from: proxy
              to: proxy
              label: Verify signature
              json_preview: 'verify(sig_base, signature, public_key) -> true'
            - from: proxy
              to: merchant
              label: Forward (verified)
              json_preview: '{"headers":{"X-Agent-Verified":"true","X-Agent-KeyId":"agent-key-123"}}'

        - title: Apply merchant policy (allow/deny/step-up)
          description: >-
            After verification, merchants can apply consistent controls: allow specific endpoints,
            require step-up confirmation for risky actions, throttle, or deny.
          actors_visible: [merchant]
          messages:
            - from: merchant
              to: merchant
              label: Policy decision
              json_preview: 'if verified && endpoint in allowlist -> allow; else -> step_up'
            - from: merchant
              to: proxy
              label: Step-up required (example)
              json_preview: '{"status":"needs_user_confirm","challenge_uri":"https://merchant.example/confirm?session=s-9"}'

  # ── Frontier (locked by default; rocket unlocks) ──────────────────
  - id: agent-audit
    title: Agent Audit Traces
    icon_alt: "log"
    tagline: Portable, vendor-neutral run records
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "OpenTelemetry Traces", url: "https://opentelemetry.io/docs/concepts/signals/traces/" }
        - { label: "OpenTelemetry GenAI semantic conventions", url: "https://opentelemetry.io/docs/specs/semconv/gen-ai/" }
        - { label: "OpenInference specification", url: "https://arize-ai.github.io/openinference/spec/" }
        - { label: "W3C PROV (provenance model)", url: "https://www.w3.org/TR/prov-overview/" }
      what_it_solves: >-
        As agents take multi-step actions — calling models, invoking tools,
        reading/writing files, spending money — operators need structured,
        portable records of what happened. Today, traces are often vendor-
        specific logs or ad hoc JSON blobs, making cross-system debugging,
        governance, and evaluation difficult.
        Agent Audit Traces define a common event model for agent runs:
        model calls, tool invocations, artifacts, decisions, and user intent
        attachments — all expressed in a trace format compatible with
        mainstream observability tooling.
      how_its_standardizing: >-
        Convergence is forming around OpenTelemetry as the substrate:
        - OTel Traces provide the span/event model.
        - OTel GenAI semantic conventions define fields for LLM calls
          (model name, token counts, prompts, completions).
        - OpenInference extends OTel with practical LLM/agent attributes
          (tool calls, chain-of-thought redaction markers, evaluation hooks).
        Meanwhile, W3C PROV provides a conceptual provenance model
        (agents, activities, entities) that maps cleanly onto span graphs.
        No single “Agent Trace RFC” exists yet, but the ecosystem is clearly
        layering agent semantics on top of OTel-compatible traces.
      virtuous_cycle:
        - "Agent frameworks emit traces for their specific users."
        - "Users develop tooling to analyze and visualize traces."
        - "Other frameworks adopt the same traces to take advantage of the tooling."
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: agent
        - id: model
          label: LLM Provider
          type: server
        - id: tool
          label: Tool
          type: server
        - id: trace
          label: OTel Collector / Trace Store
          type: server
        - id: auditor
          label: Operator / Auditor
          type: app

      scenes:
        - title: Root span for an agent run
          description: >-
            A new trace begins when an agent run starts. The root span
            represents the user goal and high-level execution context.
          actors_visible: [agent, trace]
          messages:
            - from: agent
              to: trace
              label: start root span
              json_preview: '{"trace_id":"abc123","span":"agent.run","attributes":{"goal":"fix failing tests"}}'
              json_full: |
                {
                  "trace_id": "abc123",
                  "span_id": "root-1",
                  "name": "agent.run",
                  "attributes": {
                    "agent.name": "CI Agent",
                    "agent.version": "1.4.0",
                    "goal": "Fix failing tests",
                    "user.id": "user-42"
                  }
                }

        - title: Model call span (GenAI semantic conventions)
          description: >-
            A child span records the LLM call with standardized GenAI attributes.
          actors_visible: [agent, model, trace]
          messages:
            - from: agent
              to: model
              label: call model
              json_preview: '{"model":"gpt-4o","messages":[...]}'
            - from: agent
              to: trace
              label: span (genai)
              json_preview: '{"span":"genai.request","attributes":{"genai.model":"gpt-4o","genai.prompt_tokens":812}}'
              json_full: |
                {
                  "trace_id": "abc123",
                  "parent_span_id": "root-1",
                  "span_id": "model-1",
                  "name": "genai.request",
                  "attributes": {
                    "genai.system": "openai",
                    "genai.model": "gpt-4o",
                    "genai.prompt_tokens": 812,
                    "genai.completion_tokens": 153,
                    "genai.finish_reason": "tool_calls"
                  }
                }

        - title: Tool call span (OpenInference-style extension)
          description: >-
            Tool invocations are captured as structured child spans,
            with arguments, result summaries, and exit codes.
          actors_visible: [agent, tool, trace]
          sparkle: true
          messages:
            - from: agent
              to: tool
              label: execute
              json_preview: '{"tool":"shell","command":"pytest"}'
            - from: agent
              to: trace
              label: span (tool)
              json_preview: '{"span":"tool.call","attributes":{"tool.name":"shell","exit_code":1}}'
              json_full: |
                {
                  "trace_id": "abc123",
                  "parent_span_id": "root-1",
                  "span_id": "tool-1",
                  "name": "tool.call",
                  "attributes": {
                    "tool.name": "shell",
                    "tool.command": "pytest",
                    "tool.exit_code": 1,
                    "tool.stdout.truncated": true
                  }
                }

        - title: Artifact reference (provenance linkage)
          description: >-
            Instead of embedding large outputs, traces link to artifacts
            (files, datasets, screenshots) via URIs.
          actors_visible: [agent, trace]
          messages:
            - from: agent
              to: trace
              label: event (artifact)
              json_preview: '{"event":"artifact","uri":"s3://runs/abc123/screenshot.png"}'
              json_full: |
                {
                  "trace_id": "abc123",
                  "span_id": "tool-1",
                  "events": [{
                    "name": "artifact.created",
                    "attributes": {
                      "artifact.uri": "s3://runs/abc123/screenshot.png",
                      "artifact.type": "image/png"
                    }
                  }]
                }

        - title: Cross-vendor audit & replay
          description: >-
            An operator loads the trace in any OTel-compatible backend
            to inspect the full execution graph across models and tools.
          actors_visible: [auditor, trace]
          sparkle: true
          messages:
            - from: auditor
              to: trace
              label: query trace
              json_preview: 'GET /traces/abc123'
            - from: trace
              to: auditor
              label: span graph
              json_preview: '{"trace_id":"abc123","spans":4,"root":"agent.run"}'

  - id: ap2
    title: AP2
    badge: unclear_adoption
    icon_alt: "pay"
    tagline: Agent-to-agent payments
    detail:
      links:
        - { label: "Specification", url: "https://ap2-protocol.org/specification/" }
      what_it_solves: >-
        Agents that transact on behalf of users need a standard way to
        request, authorize, and settle payments — with cryptographic
        proof of user consent and spending limits. AP2 defines payment
        mandates that bind user intent to agent actions.
      how_its_standardizing: >-
        Open specification for agent-initiated payments. Defines mandate
        objects with scope, limits, and TTL that travel with payment
        requests. Designed to work alongside identity protocols like
        TAP and Web Bot Auth.
      virtuous_cycle:
        - "Agents can transact across merchants with verifiable authorization."
        - "Merchants get cryptographic proof of user consent, reducing fraud."
        - "Payment rails gain a standard agent interface instead of per-agent integrations."
    animation:
      actors:
        - id: agent
          label: Paying Agent
          type: agent
        - id: merchant
          label: Merchant
          type: merchant
        - id: wallet
          label: Wallet
          type: server
      scenes:
        - title: Present payment mandate
          description: >-
            The agent submits a signed mandate proving user authorization
            and spending limits.
          actors_visible: [agent, merchant]
          messages:
            - from: agent
              to: merchant
              label: pay
              json_preview: '{"mandate_id":"m-123","amount":4999}'
        - title: Settle payment
          description: >-
            The merchant verifies the mandate and settles through a
            compatible payment rail.
          actors_visible: [merchant, wallet]
          sparkle: true
          messages:
            - from: merchant
              to: wallet
              label: charge
              json_preview: '{"mandate_id":"m-123"}'

  - id: intent-mandates
    title: Signed Intent Mandates
    badge: speculative
    icon_alt: "sig"
    tagline: Portable, machine-verifiable authorization artifacts
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "AP2 Specification (Intent Mandate)", url: "https://ap2-protocol.org/specification/" }
        - { label: "OAuth 2.0 Rich Authorization Requests (RFC 9396)", url: "https://oauth.net/2/rich-authorization-requests/" }
        - { label: "Kantara Consent Receipt (background)", url: "https://kantarainitiative.org/confluence/display/infosharing/Consent+Receipt+Specification" }
      what_it_solves: >-
        Agents increasingly act on behalf of users across domains — payments,
        IT operations, data access, procurement, healthcare. Today, user consent
        and constraints are typically expressed through vendor-specific tokens,
        coarse OAuth scopes, or opaque session state.
        Signed Intent Mandates generalize a pattern: a structured, signed object
        that binds user intent and constraints (scope, resource, limits, TTL,
        revocation conditions) to downstream agent actions in a portable way.
      how_its_standardizing: >-
        This pattern has strong adjacent precedents but no unified cross-domain
        standard yet.
        - AP2 defines an "Intent Mandate" for agent-initiated payments.
        - OAuth Rich Authorization Requests (RFC 9396) standardize structured,
          fine-grained authorization parameters.
        - Consent receipt standards define portable consent artifacts.
        A generalized Signed Intent Mandate layer would converge these ideas into
        a reusable interop object for arbitrary agent actions.
        Standardization is likely to begin in regulated domains (finance, healthcare,
        enterprise IT) and then expand as multi-agent coordination increases.
      virtuous_cycle:
        - "Users of agents become more comfortable allowing agents to act on their behalf."
        - "Businesses offer narrow intent mandates to encourage users to work with them."
    animation:
      actors:
        - id: user
          label: User
          type: app
        - id: wallet
          label: Intent Wallet / Identity Provider
          type: server
        - id: agent
          label: Agent
          type: agent
        - id: service
          label: Service
          type: server
      scenes:
        - title: User defines structured intent
          description: >-
            The user specifies constraints for an action: what resource,
            what limits, and how long the authorization lasts.
          actors_visible: [user, wallet]
          messages:
            - from: user
              to: wallet
              label: Create intent
              json_preview: '{"action":"deploy","resource":"cluster-7","ttl":"1h","max_cost":"$50"}'
              json_full: |
                {
                  "action": "deploy",
                  "resource": "cluster-7",
                  "constraints": {
                    "ttl": "1h",
                    "max_cost": 50,
                    "currency": "USD"
                  }
                }

        - title: Wallet issues signed mandate
          description: >-
            The identity provider or wallet signs the intent object,
            producing a portable mandate artifact.
          actors_visible: [wallet, agent]
          messages:
            - from: wallet
              to: agent
              label: Signed mandate
              json_preview: '{"mandate_id":"m-42","signature":"BASE64..."}'
              json_full: |
                {
                  "mandate_id": "m-42",
                  "issuer": "wallet.example",
                  "subject": "user-123",
                  "intent": {
                    "action": "deploy",
                    "resource": "cluster-7",
                    "constraints": {
                      "ttl": "1h",
                      "max_cost": 50,
                      "currency": "USD"
                    }
                  },
                  "issued_at": "2026-02-13T14:00:00Z",
                  "expires_at": "2026-02-13T15:00:00Z",
                  "signature": "BASE64_SIGNATURE"
                }

        - title: Agent presents mandate to service
          description: >-
            The agent attaches the mandate to its request. The service
            verifies signature, expiration, and constraints before execution.
          actors_visible: [agent, service]
          sparkle: true
          messages:
            - from: agent
              to: service
              label: Authorized request
              json_preview: '{"mandate_id":"m-42","operation":"deploy"}'
            - from: service
              to: service
              label: Verify + enforce constraints
              json_preview: 'verify(signature) && now < expires_at && cost <= 50 -> allow'

  - id: agent-registries
    title: Agent Registries
    icon_alt: "dir"
    tagline: Discovery, routing, permissions
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Draft (example)", url: "https://datatracker.ietf.org/doc/draft-narvaneni-agent-uri/" }
      what_it_solves: >-
        A standard directory for agents: capability queries, routing,
        health/versioning, and enterprise entitlements.
      how_its_standardizing: >-
        Likely to emerge from enterprise catalogs and public indexes
        that aggregate AgentCard descriptors. A2A's well-known discovery
        provides the base layer; registries add search, ACLs, and routing.
      virtuous_cycle:
        - "Enterprises can safely compose multi-vendor agent systems."
        - "Vendors plug into one directory surface instead of bespoke integrations."
        - "Governance (who can call what) becomes portable."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: registry
          label: Registry
          type: registry
      scenes:
        - title: Query registry
          description: >-
            An agent searches a registry for other agents matching
            required capabilities.
          actors_visible: [agent, registry]
          messages:
            - from: agent
              to: registry
              label: search
              json_preview: '{"skill":"invoice-extraction"}'
            - from: registry
              to: agent
              label: results
              json_preview: '[{"agent":"InvoiceAgent"}]'

  - id: agent-lingua
    title: Agent Lingua Franca
    icon_alt: "αβ"
    tagline: Efficient machine-to-machine semantics
    badge: speculative
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Emergent communication (survey example)", url: "https://arxiv.org/abs/2006.02419" }
        - { label: "Communicating Activations Between LMs", url: "https://arxiv.org/abs/2501.14082" }
        - { label: "Translating Neuralese", url: "https://aclanthology.org/P17-1022/" }
      what_it_solves: >-
        When agents communicate today, they use natural language or verbose JSON.
        Both are optimized for human readability, not bandwidth, latency, or
        cross-model efficiency. As multi-agent orchestration scales, token costs,
        context windows, and serialization overhead become material constraints.
        An Agent Lingua Franca would define a shared, more compact semantic layer
        for inter-agent communication.
      how_its_standardizing: >-
        No dominant approach exists. Convergence could occur through:
        (1) shared symbolic codebooks layered on A2A,
        (2) learned shorthand via multi-agent reinforcement learning,
        (3) latent-space exchange (embeddings, activations, KV caches),
        or (4) compression layers negotiated between compatible agents.
        Any viable standard would likely require explicit capability negotiation
        and fallback to human-readable formats.
        Significant headwinds include interpretability, auditability,
        regulatory requirements, and tokenizer/model incompatibilities.
      virtuous_cycle:
        - "High traffic agents in controlled situations are optimized for efficiency."
        - "Additional agents that would benefit from joining lead to standardized interop."
    animation:
      actors:
        - id: agent-a
          label: Agent A
          type: agent
        - id: agent-b
          label: Agent B
          type: agent
        - id: store
          label: Shared Artifact Store
          type: server

      scenes:
        - title: Symbolic codebook exchange
          description: >-
            Agents negotiate a compact symbolic vocabulary for a task domain.
            Symbols reference shared semantics instead of verbose text.
          actors_visible: [agent-a, agent-b]
          messages:
            - from: agent-a
              to: agent-b
              label: negotiate codebook
              json_preview: '{"codebook_version":"v3","symbols":{"Δ7":"apply_patch","Ω2":"run_tests"}}'
            - from: agent-b
              to: agent-a
              label: ack
              json_preview: '{"accepted":"v3"}'
            - from: agent-a
              to: agent-b
              label: compressed task
              json_preview: '{"op":"Δ7","args":["file.py"]}'

        - title: Learned shorthand (RL-evolved)
          description: >-
            Through repeated interaction, agents converge on shorter
            sequences that preserve mutual task performance.
          actors_visible: [agent-a, agent-b]
          sparkle: true
          messages:
            - from: agent-a
              to: agent-b
              label: shorthand
              json_preview: '{"msg":"⟦A3⟧"}'
            - from: agent-b
              to: agent-a
              label: decoded action
              json_preview: '{"interpretation":"fetch dependency graph"}'

        - title: Latent exchange (non-text channel)
          description: >-
            Compatible agents exchange intermediate representations
            (e.g., embeddings or KV-cache slices) instead of tokens.
            The message is opaque to humans but semantically meaningful
            to aligned model architectures.
          actors_visible: [agent-a, agent-b]
          sparkle: true
          messages:
            - from: agent-a
              to: agent-b
              label: latent payload
              json_preview: '{"type":"kv-slice","layers":[8,9,10],"shape":[3,4096]}'

        - title: Artifact-by-reference compression
          description: >-
            Instead of transmitting full state repeatedly, agents exchange
            short references to shared artifacts, minimizing repeated context.
          actors_visible: [agent-a, agent-b, store]
          messages:
            - from: agent-a
              to: store
              label: store state
              json_preview: 'PUT /artifacts/s-77'
            - from: agent-a
              to: agent-b
              label: reference
              json_preview: '{"ref":"s-77","delta":"Δ3"}'
            - from: agent-b
              to: store
              label: fetch state
              json_preview: 'GET /artifacts/s-77'
  - id: interoperable-memory
    title: Interoperable Memory
    icon_alt: "mem"
    tagline: Portable user context across agents
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "New America: AI Agents and Memory", url: "https://www.newamerica.org/oti/reports/ai-agents-and-memory/" }
        - { label: "Stanford HCP Project", url: "https://digitaleconomy.stanford.edu/project/loyal-agents/hcp-human-context-protocol/" }
        - { label: "OAuth 2.0 Rich Authorization Requests (RFC 9396)", url: "https://www.rfc-editor.org/rfc/rfc9396" }
        - { label: "Sam Altman interview: Memory is OpenAI's real moat", url: "https://www.cmswire.com/digital-experience/i-spoke-with-sam-altman-what-openais-future-actually-looks-like/" }
      what_it_solves: >-
        Often, long-term memory (preferences, goals, constraints, past interactions)
        is stored inside individual assistant products. This creates lock-in:
        switching agents means losing personalization, history, and accumulated trust.
        Interoperable Memory moves to user context
        that is portable, inspectable, and permissioned across services,
        not trapped inside a single vendor's assistant.
      how_its_standardizing: >-
        There is not yet a dominant protocol. Instead, several strands are converging:

        - Policy framing (e.g., New America) argues for interoperable memory
          dashboards and user-controlled portability as a governance baseline.
        - Research proposals like Stanford's Human Context Protocol (HCP)
          sketch a clean architectural boundary between agents and an external
          user-aligned context manager.
        - Existing web standards like OAuth Rich Authorization Requests (RFC 9396)
          provide a substrate for fine-grained, structured consent when agents
          read or update user state.

        The likely direction is not a single “memory file format,” but a layered
        stack: standardized consent + schema declaration + query/update APIs
        for user-controlled context stores.
      virtuous_cycle:
        - "Users of open source agents converge on a memory standard."
        - "One commercial agent vendor adopts the standard to gains a competitive advantage."
        - "Other commercial agent vendors adopt the standard to remain feature parity."

    animation:
      actors:
        - id: user
          label: User
          type: app
        - id: agent-a
          label: Agent A
          type: agent
        - id: agent-b
          label: Agent B
          type: agent
        - id: memory
          label: User Context Store
          type: server

      scenes:
        - title: Vendor-locked memory (status quo)
          description: >-
            Agent A stores preferences internally. Switching agents
            means starting from scratch.
          actors_visible: [user, agent-a]
          messages:
            - from: user
              to: agent-a
              label: Set preference
              json_preview: '{"tone":"concise","units":"metric"}'
            - from: agent-a
              to: agent-a
              label: Store internally
              json_preview: '{"memory":"proprietary_store"}'

        - title: Externalized context store
          description: >-
            Preferences are stored in a user-aligned context manager,
            separate from any single agent.
          actors_visible: [user, agent-a, memory]
          sparkle: true
          messages:
            - from: agent-a
              to: memory
              label: Define schema
              json_preview: '{"namespace":"prefs","fields":["tone","units"]}'
            - from: agent-a
              to: memory
              label: Write preference
              json_preview: '{"key":"units","value":"metric"}'

        - title: Fine-grained authorization
          description: >-
            Access to memory is governed by structured, explicit consent
            rather than blanket data sharing.
          actors_visible: [user, agent-b, memory]
          messages:
            - from: agent-b
              to: user
              label: Request access
              json_preview: '{"authorization_details":{"type":"memory.read","namespace":"prefs"}}'
            - from: user
              to: agent-b
              label: Grant scoped consent
              json_preview: '{"grant":"read:prefs","ttl":"24h"}'

        - title: Agent portability
          description: >-
            Agent B reads the same context store using the same interface.
            User familiarity travels across services.
          actors_visible: [agent-b, memory]
          sparkle: true
          messages:
            - from: agent-b
              to: memory
              label: Query prefs
              json_preview: '{"query":"units","top_k":1}'
            - from: memory
              to: agent-b
              label: Preference
              json_preview: '{"key":"units","value":"metric"}'