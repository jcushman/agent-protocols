title: The Agent Protocol Tech Tree
subtitle: How open standards for AI agents emerge layer by layer
details: |
  Open protocols emerge when decentralized parties benefit from speaking the same language.
  If your software will be used more when it outputs data that other software can read,
  and reads data that other software produces, all tools tend to converge on a common format.
  AI agents are currently incentivized to converge in this way, and are rapidly exploring
  and adopting standards. This tool explores
  the standards they are converging on and why each layer came to be.


# ── Tree ──────────────────────────────────────────────────────────────
# Defines hierarchy and visual layout.  Nesting = parent → child.
# extra_cols:     additional columns beyond default (first_parent_col + 1).
# extra_parents:  additional parent connections drawn on the tree.
# Column formula: first_parent_col + 1 + extra_cols (default 0); roots with no parents: 0.
# Sibling order controls vertical positioning within a column.
#
# Clusters are first-class tree nodes with `cluster: true` and `items:`.
# They render as dashed-outline group boxes containing their items.
# Both clusters and their individual items can have parent/child arrows.

tree:
  - id: c-foundations
    cluster: true
    label: Model building standards
    description: >-
      These are the low-level file formats and conventions that let open weight model
      move between training, distribution, and inference.
      None were designed by a standards body; each emerged because model publishers
      and runtime authors converged on the same artifacts.
    items:
      - id: tokenizers
      - id: weight-formats
      - id: embeddings
      - id: chat-templates
    children:
      - id: inference-api
        children:
          - id: tool-calling
            children:
              - id: mcp
                children:
                  - id: mcp-apps
              - id: standard-tool-surfaces
                children:
              - id: agent-loop
                extra_cols: 1
                extra_parents: [standard-tools]
                children:
                  - id: c-context-management
                    cluster: true
                    display: node
                    label: Context Management
                    description: >-
                      As agents engage more with the world, they need ways to fetch updated information
                      about how to handle specific situations.
                    items:
                      - id: agents-md
                      - id: llms-txt
                      - id: agent-skills
                        children:
                          - id: agent-skills-discovery
                          - id: agent-skills-registries
                  - id: c-interagent
                    cluster: true
                    display: node
                    label: Inter-agent Coordination
                    description: >-
                      The desire to automate large enterprises (or to sell services to them) drives
                      protocols for agents within an enterprise to coordinate their work, potentially across vendors;
                      analogous to existing service discovery layers within enterprises.
                    items:
                      - id: agent-card
                        children:
                          - id: a2a
                          - id: agent-registries
                      - id: agent-lingua
                  - id: c-trust
                    cluster: true
                    display: node
                    label: Trust & Delegation
                    description: >-
                      Identity, signatures, and delegated authority. These protocols let
                      agents prove who is calling, carry user authorization, and enforce
                      constraints like spending limits and TTLs — whether the counterpart
                      is another agent or a deterministic API.
                    items:
                      - id: agent-identity
                      - id: ucp
                      - id: ap2
                        children:
                          - id: intent-mandates
                  - id: c-user-controls
                  - id: agent-audit
                  - id: human-context-protocol

# ── Technologies ────────────────────────────────────────────────────
# unlock.state: locked | unlocked (default unlocked).
# unlock.class: foundational | frontier (determines overlay icon).

technologies:

  # ── Foundations (locked by default; stone-age unlocks) ─────────────
  - id: tokenizers
    toc_group: 1
    title: Tokenizers
    icon_alt: "tok"
    tagline: Portable text-to-token boundary
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "Hugging Face Tokenizers", url: "https://github.com/huggingface/tokenizers" }
        - { label: "SentencePiece", url: "https://github.com/google/sentencepiece" }
      what_it_solves: >-
        Model publishers and runtimes must agree on a shared on-disk artifact with identical encode/decode semantics.
      how_its_standardizing: >-
        Converged through de facto artifacts (vocab/merges, SentencePiece models,
        tokenizer.json) adopted by model publishers and runtimes rather than a
        formal standards body.
      virtuous_cycle:
        - "Model publishers ship a tokenizer artifact so downstream users can run the model."
        - "Runtime/tooling authors implement the common artifacts to support many models."
        - "New models choose widely supported tokenizer formats to maximize portability."
    animation:
      actors:
        - id: repo
          label: Model Repo
          type: repo
        - id: runtime
          label: Runtime / Server
          type: server
      scenes:
        - title: BPE artifacts (vocab + merges)
          description: >-
            Many tokenizers standardize as a pair of files. Runtimes must interpret
            them identically so the same text produces the same token ids.
          actors_visible: [repo, runtime]
          messages:
            - from: runtime
              to: repo
              label: Fetch vocab.json
              json_preview: 'GET /vocab.json'
            - from: repo
              to: runtime
              label: vocab.json
              json_preview: '{"l":0,"o":1,"w":2,"lo":3,"low":4,"er":5,"lower":6}'
            - from: runtime
              to: repo
              label: Fetch merges.txt
              json_preview: 'GET /merges.txt'
            - from: repo
              to: runtime
              label: merges.txt
              json_preview: 'l o\nlo w\nlow er'
            - from: runtime
              to: repo
              label: Deterministic tokenize()
              json_preview: 'tokenize("lower") -> [6]'

        - title: SentencePiece model file
          description: >-
            Other ecosystems converge on a single binary artifact (SentencePiece).
            The runtime only needs the shared loader to get identical pieces + ids.
          actors_visible: [repo, runtime]
          sparkle: true
          messages:
            - from: runtime
              to: repo
              label: Fetch tokenizer.model
              json_preview: 'GET /tokenizer.model'
            - from: repo
              to: runtime
              label: SentencePiece model (binary)
              json_preview: 'pieces=["▁Hello","▁world","!"] ids=[101,102,7]'

        - title: tokenizer.json as a unified portability target
          description: >-
            Some publishers ship tokenizer.json so many runtimes can load one format.
            This becomes a de facto interchange artifact across tools.
          actors_visible: [repo, runtime]
          sparkle: true
          messages:
            - from: runtime
              to: repo
              label: Fetch tokenizer.json
              json_preview: 'GET /tokenizer.json'
            - from: repo
              to: runtime
              label: tokenizer.json (subset)
              json_preview: '{"model":{"type":"BPE"},"pre_tokenizer":{"type":"Whitespace"}}'
            - from: runtime
              to: repo
              label: Same artifact, same ids
              json_preview: 'tokenize("hello world") -> [0,1]'

  - id: weight-formats
    toc_group: 1
    title: Weight Formats
    icon_alt: "w"
    tagline: Safe model distribution
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "safetensors", url: "https://github.com/huggingface/safetensors" }
        - { label: "GGUF / llama.cpp", url: "https://github.com/ggerganov/llama.cpp" }
      what_it_solves: >-
        A safe, fast way to distribute model tensors across frameworks and runtimes.
      how_its_standardizing: >-
        De facto convergence on formats like safetensors (safety/perf) and GGUF
        (local inference ecosystem), driven by tool support and publishing norms.
      virtuous_cycle:
        - "Publishers pick formats that load everywhere with minimal risk."
        - "Runtimes support formats that unlock the largest model catalog."
        - "Converters/quantizers flourish once a stable on-disk format is common."

  - id: embeddings
    toc_group: 1
    title: Embeddings
    icon_alt: "vec"
    tagline: Universal vector interface
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "Standard", url: "https://opensearch.org/docs/latest/search-plugins/knn/" }
      what_it_solves: >-
        A universal "vector + metadata" interface enabling retrieval, semantic search,
        and RAG pipelines regardless of the embedding model or vector store.
      how_its_standardizing: >-
        Converged by API similarity across vector DBs and common client expectations
        (float[] vectors, metadata filters, upsert/query) rather than a single spec.
      virtuous_cycle:
        - "Apps rely on a stable vector interface; swapping stores/models becomes easy."
        - "DBs adopt common ops (upsert/query/filter) to capture the same client ecosystem."
        - "Model providers target vector-friendly shapes to plug into common retrieval stacks."

  - id: chat-templates
    toc_group: 1
    title: Chat Templates
    icon_alt: "msg"
    tagline: Portable conversation format
    unlock: { state: locked, class: foundational }
    detail:
      links:
        - { label: "Standard", url: "https://huggingface.co/docs/transformers/main/chat_templating" }
      what_it_solves: >-
        A portable way to represent multi-turn conversations and serialize them into
        model-specific token sequences correctly.
      how_its_standardizing: >-
        Dataset schemas converged on role/content turns; chat template metadata
        (e.g., in tokenizers/configs) enabled generic chat UIs to support many models.
      virtuous_cycle:
        - "Apps can target a consistent message schema across models."
        - "Model publishers ship templates so generic clients can format prompts correctly."
        - "Evaluation/training pipelines reuse the same role/content structure at scale."

  # ── Inference ─────────────────────────────────────────────────────
  - id: inference-api
    title: Inference API
    icon_alt: ">_"
    tagline: A stable way to talk to any model
    detail:
      links:
        - { label: "Standard", url: "https://platform.openai.com/docs/api-reference/chat" }
        - { label: "Ollama compatibility", url: "https://github.com/ollama/ollama/blob/main/docs/openai.md" }
        - { label: "OpenRouter", url: "https://openrouter.ai/docs/quickstart" }
      what_it_solves: >-
        Applications needed a consistent way to send prompts to language
        models and receive responses — without rewriting code for every
        provider. The chat completions API shape gave developers a single
        interface to target, making LLMs a reliable, swappable component.
      how_its_standardizing: >-
        OpenAI's Chat Completions API (March 2023) became the reference
        design for chat-shaped request/response. Many SDKs, gateways, and
        open-source servers (Ollama, vLLM, llama.cpp) expose OpenAI-compatible
        endpoints. Aggregators like OpenRouter expose hundreds of models behind
        the same API. New entrants like DeepSeek ship compatible APIs from
        day one to tap into the existing ecosystem immediately.
      virtuous_cycle:
        - "App makers target one interface and can switch providers with minimal changes."
        - "Model hosts gain adoption by being drop-in compatible with existing clients."
        - "Tooling (SDKs, gateways, proxies) compounds around the common shape."
    animation:
      actors:
        - id: app
          label: Your App
          type: app
        - id: openai
          label: OpenAI
          type: server
        - id: openrouter
          label: OpenRouter
          type: server
        - id: ollama
          label: Ollama (Local)
          type: server
        - id: deepseek
          label: DeepSeek
          type: server
      scenes:
        - title: App talks to a model provider
          description: >-
            Your application sends a chat completion request to OpenAI
            using the standard message format.
          actors_visible: [app, openai]
          messages:
            - from: app
              to: openai
              label: Chat prompt
              json_preview: '{"model":"gpt-4","messages":[{"role":"user","content":"Hello"}]}'
              json_full: |
                POST /v1/chat/completions
                {
                  "model": "gpt-4",
                  "messages": [
                    {"role": "user", "content": "Hello, how are you?"}
                  ],
                  "temperature": 0.7,
                  "max_tokens": 256
                }
            - from: openai
              to: app
              label: Completion
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hi there!"}}]}'
              json_full: |
                {
                  "id": "chatcmpl-abc123",
                  "object": "chat.completion",
                  "model": "gpt-4",
                  "choices": [{
                    "index": 0,
                    "message": {
                      "role": "assistant",
                      "content": "Hi there! How can I help you today?"
                    },
                    "finish_reason": "stop"
                  }],
                  "usage": {
                    "prompt_tokens": 12,
                    "completion_tokens": 9,
                    "total_tokens": 21
                  }
                }
        - title: Same code, any model via aggregator
          description: >-
            Switch to OpenRouter and access hundreds of models from
            different providers — the request and response shape stay the same.
          actors_visible: [app, openrouter]
          sparkle: true
          messages:
            - from: app
              to: openrouter
              label: Same format
              json_preview: '{"model":"anthropic/claude-sonnet-4","messages":[{"role":"user","content":"Hello"}]}'
            - from: openrouter
              to: app
              label: Same shape response
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hello!"}}]}'
        - title: Even works locally
          description: >-
            Ollama runs models on your own machine — and speaks the
            same API. One interface, every model.
          actors_visible: [app, ollama]
          sparkle: true
          messages:
            - from: app
              to: ollama
              label: Same format, locally
              json_preview: '{"model":"llama3","messages":[{"role":"user","content":"Hello"}]}'
            - from: ollama
              to: app
              label: Same shape response
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hey there!"}}]}'
        - title: New models launch pre-compatible
          description: >-
            When DeepSeek launched its R1 model, it shipped an
            OpenAI-compatible API from day one — instant access for
            every app already targeting the standard.
          actors_visible: [app, deepseek]
          sparkle: true
          messages:
            - from: app
              to: deepseek
              label: Same format, new model
              json_preview: '{"model":"deepseek-reasoner","messages":[{"role":"user","content":"Hello"}]}'
            - from: deepseek
              to: app
              label: Same shape response
              json_preview: '{"choices":[{"message":{"role":"assistant","content":"Hello! How can I help?"}}]}'

  # ── Tool Calling ──────────────────────────────────────────────────
  - id: tool-calling
    title: Tool Calling
    icon_alt: "f(x)"
    tagline: Models that can take action
    detail:
      links:
        - { label: "Launch", url: "https://openai.com/index/function-calling-and-other-api-updates/" }
        - { label: "Standard", url: "https://platform.openai.com/docs/guides/function-calling" }
      what_it_solves: >-
        Language models can only generate text — but applications need
        them to take real actions like searching the web, reading files,
        or calling APIs. Tool calling lets a model emit structured
        "call this function" requests, and then continue after the app
        executes them. Tool definitions use JSON Schema-like structures,
        making tools portable and machine-readable across providers.
      how_its_standardizing: >-
        OpenAI introduced "function calling" in June 2023, later
        generalized to "tool calling." Other providers rapidly adopted
        the same pattern. Standardization is de facto: JSON Schema-inspired
        signatures and tool-call/result message roles work across providers,
        though implementations vary slightly in supported schema features.
      virtuous_cycle:
        - "App makers expose capabilities once and reuse them across many models."
        - "Model makers support tool calling to be useful in real workflows, not just chat."
        - "Tool ecosystems emerge because definitions are machine-readable and reusable."
    animation:
      actors:
        - id: app
          label: Your App
          type: app
        - id: model
          label: LLM
          type: model
      scenes:
        - title: App provides tools to the model
          description: >-
            The app sends a prompt along with tool definitions
            describing what functions are available.
          actors_visible: [app, model]
          messages:
            - from: app
              to: model
              label: Prompt + tool definitions
              json_preview: '{"messages":[...],"tools":[{"type":"function","function":{"name":"search"}}]}'
              json_full: |
                POST /v1/chat/completions
                {
                  "model": "gpt-4",
                  "messages": [
                    {"role": "user", "content": "What's the weather in Boston?"}
                  ],
                  "tools": [{
                    "type": "function",
                    "function": {
                      "name": "get_weather",
                      "description": "Get current weather for a location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {"type": "string"}
                        },
                        "required": ["location"]
                      }
                    }
                  }]
                }
        - title: Model requests a tool call
          description: >-
            Instead of answering directly, the model emits a structured
            tool call — requesting the app to execute a function.
          actors_visible: [app, model]
          messages:
            - from: model
              to: app
              label: tool_call
              json_preview: '{"tool_calls":[{"function":{"name":"get_weather","arguments":"{\"location\":\"Boston\"}"}}]}'
              json_full: |
                {
                  "choices": [{
                    "message": {
                      "role": "assistant",
                      "tool_calls": [{
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_weather",
                          "arguments": "{\"location\": \"Boston, MA\"}"
                        }
                      }]
                    },
                    "finish_reason": "tool_calls"
                  }]
                }
        - title: App executes and returns the result
          description: >-
            The app runs the function and sends the result back.
            The model incorporates it into its final answer.
          actors_visible: [app, model]
          messages:
            - from: app
              to: model
              label: Tool result
              json_preview: '{"role":"tool","content":"{\"temp\":\"62F\",\"condition\":\"Partly cloudy\"}"}'
              json_full: |
                {
                  "messages": [
                    {"role": "user", "content": "What's the weather in Boston?"},
                    {"role": "assistant", "tool_calls": [{"id": "call_abc123", "type": "function", "function": {"name": "get_weather", "arguments": "{\"location\": \"Boston, MA\"}"}}]},
                    {"role": "tool", "tool_call_id": "call_abc123", "content": "{\"temp\": \"62F\", \"condition\": \"Partly cloudy\", \"humidity\": \"45%\"}"}
                  ]
                }
            - from: model
              to: app
              label: Final answer
              json_preview: '{"content":"It''s 62F and partly cloudy in Boston."}'

  # ── MCP ───────────────────────────────────────────────────────────
  - id: mcp
    title: MCP
    icon_alt: "<>"
    tagline: One protocol for every tool
    detail:
      links:
        - { label: "Launch", url: "https://www.anthropic.com/news/model-context-protocol" }
        - { label: "Spec (2025-03-26)", url: "https://modelcontextprotocol.io/specification/2025-03-26" }
        - { label: "AAIF governance", url: "https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation" }
      what_it_solves: >-
        Now models can call tools — but without MCP, connecting N apps to M tool providers requires N*M
        custom integrations. MCP defines a single client/server protocol
        so any app can discover and use any tool server — just run tools/list to
        find what's available, tools/call to use it, with a standard way to
        authenticate to private servers.
      how_its_standardizing: >-
        Introduced by Anthropic (November 2024). Rapidly adopted across
        the agent tooling ecosystem. Now under open governance through
        the Agentic AI Foundation (AAIF) at the Linux Foundation, with
        community contributions and a growing ecosystem of client and
        server implementations.
      virtuous_cycle:
        - "Tool providers implement one server and reach many MCP clients."
        - "Clients add one protocol and gain access to a growing tool catalog."
        - "Shared conventions reduce integration cost and accelerate new tools."
    animation:
      actors:
        - id: app
          label: Claude
          type: app
        - id: file-server
          label: File Server
          type: server
        - id: db-server
          label: DB Server
          type: server
        - id: cursor
          label: Cursor
          type: app
      scenes:
        - title: Client discovers server tools
          description: >-
            An MCP client connects to a file server and asks what
            tools are available using the standard tools/list method.
          actors_visible: [app, file-server]
          messages:
            - from: app
              to: file-server
              label: tools/list
              json_preview: '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
              json_full: |
                {
                  "jsonrpc": "2.0",
                  "id": 1,
                  "method": "tools/list",
                  "params": {}
                }
            - from: file-server
              to: app
              label: Available tools
              json_preview: '{"result":[{"name":"read_file","description":"Read a file"}]}'
              json_full: |
                {
                  "jsonrpc": "2.0",
                  "id": 1,
                  "result": [{
                    "name": "read_file",
                    "description": "Read a file from the filesystem",
                    "inputSchema": {
                      "type": "object",
                      "properties": {
                        "path": {"type": "string", "description": "File path to read"}
                      },
                      "required": ["path"]
                    }
                  }]
                }
        - title: Client calls a tool
          description: >-
            The client invokes a tool on the server using tools/call.
            The server executes it and returns the result.
          actors_visible: [app, file-server]
          messages:
            - from: app
              to: file-server
              label: tools/call
              json_preview: '{"method":"tools/call","params":{"name":"read_file","arguments":{"path":"README.md"}}}'
              json_full: |
                {
                  "jsonrpc": "2.0",
                  "id": 2,
                  "method": "tools/call",
                  "params": {
                    "name": "read_file",
                    "arguments": {"path": "README.md"}
                  }
                }
            - from: file-server
              to: app
              label: Tool result
              json_preview: '{"result":{"content":[{"type":"text","text":"# My Project..."}]}}'
        - title: Same client, different server
          description: >-
            The same MCP client connects to a database server.
            Same protocol — tools/list, tools/call — different tools.
          actors_visible: [app, db-server]
          sparkle: true
          messages:
            - from: app
              to: db-server
              label: tools/list
              json_preview: '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
            - from: db-server
              to: app
              label: Available tools
              json_preview: '{"result":[{"name":"query","description":"Run a SQL query"}]}'
        - title: Different client, same server
          description: >-
            A completely different app — Cursor — connects to the
            same file server. No changes needed on either side.
          actors_visible: [cursor, file-server]
          sparkle: true
          messages:
            - from: cursor
              to: file-server
              label: tools/list
              json_preview: '{"jsonrpc":"2.0","id":1,"method":"tools/list"}'
            - from: file-server
              to: cursor
              label: Same tools
              json_preview: '{"result":[{"name":"read_file","description":"Read a file"}]}'

  # ── MCP Apps ──────────────────────────────────────────────────────
  - id: mcp-apps
    title: MCP Apps
    icon_alt: "UI"
    tagline: Interactive UIs for tool servers
    detail:
      what_it_solves: >-
        MCP makes chatbots the front door to the internet — users might start to make Spotify
        playlists or buy products through their favorite chatbot rather than the original site.
        But some of those interactions might need custom UI that chatbot makers don't want to
        maintain, and some vendors might want to keep a face-to-face relationship with their
        users. MCP Apps provide a safe, controlled way for upstream services to talk 
        directly to the user without leaving their chat.
      how_its_standardizing: >-
        MCP Apps emerged as the convergence point between Anthropic's MCP ecosystem and the demand for rich, safe in-chat UI that OpenAI operationalized with the ChatGPT Apps SDK. OpenAI later documented that ChatGPT implements the MCP Apps UI standard and provides a mapping from Apps SDK patterns to MCP Apps keys, with OpenAI-only extensions as optional add-ons. The MCP community then formalized this as an official extension (modelcontextprotocol/ext-apps), explicitly describing MCP Apps as “inspired by MCP-UI and OpenAI's Apps SDK,” and standardizing the core portability/safety shape: sandboxed iframe rendering plus a host↔app messaging surface.
      virtuous_cycle:
        - "Tool providers can deliver better UX without per-host bespoke UI work."
        - "Hosts gain safer, richer interactions than pure JSON tool results."
        - "A common UI embedding model encourages more reusable tool apps."
      links:
        - label: "OpenAI: Introducing Apps in ChatGPT"
          url: "https://openai.com/index/introducing-apps-in-chatgpt/"
        - label: "OpenAI: MCP Apps in ChatGPT (Apps SDK docs)"
          url: "https://developers.openai.com/apps-sdk/mcp-apps-in-chatgpt/"
        - label: "MCP Docs: Apps Extension"
          url: "https://modelcontextprotocol.io/docs/extensions/apps"
        - label: "MCP Blog: MCP Apps Official Extension (Jan 26, 2026)"
          url: "https://blog.modelcontextprotocol.io/posts/2026-01-26-mcp-apps/"
        - label: "GitHub: modelcontextprotocol/ext-apps"
          url: "https://github.com/modelcontextprotocol/ext-apps"
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: app
        - id: tool
          label: Tool Server
          type: server
        - id: app
          label: MCP App UI
          type: app
      scenes:
        - title: Tool returns a UI surface
          description: >-
            Instead of raw JSON, the tool advertises an interactive UI
            surface that can be embedded by the host.
          actors_visible: [agent, tool]
          messages:
            - from: agent
              to: tool
              label: tools/call
              json_preview: '{"name":"inspect","arguments":{"id":"123"}}'
            - from: tool
              to: agent
              label: app descriptor
              json_preview: '{"type":"app","src":"https://tool/ui/inspect"}'
        - title: Host embeds the UI
          description: >-
            The agent host renders the UI in a sandboxed iframe and
            communicates with it via MCP messaging.
          actors_visible: [agent, app]
          sparkle: true
          messages:
            - from: agent
              to: app
              label: embed
              json_preview: '{"sandbox":true}'

  # ── Standard Tool Surfaces ────────────────────────────────────────
  - id: standard-tool-surfaces
    title: Standard Tools
    icon_alt: "cli"
    tagline: Browser, Command Line, and Code
    detail:
      what_it_solves: >-
        Some tools turn out to be so useful that model makers have to make sure
        during training that they work well, and client apps need standard ways
        to provide them. Three key tools emerge: browser, command line, and code.
      how_its_standardizing: >-
        Convergence happened through training and deployment pressure rather than
        a formal spec. Model cards (e.g., OpenAI's gpt-oss) make explicit that
        models are fine-tuned to operate browser, terminal, and code-editing tools.
        Agent platforms independently settled on similar action vocabularies
        (navigate/click/type; run/exit/stdout; apply_patch/test) because these
        abstractions cover most real-world workflows. The semantics, not the
        wire format, are what standardized.
      virtuous_cycle:
        - "Model developers train on stable tool categories to improve reliability."
        - "Hosts expose consistent tool schemas, enabling cross-model portability."
        - "Evaluation benchmarks align around the same action surfaces, reinforcing convergence."
      links:
        - { label: "OpenAI gpt-oss Model Card (example of tool-specific finetuning)", url: "https://openai.com/research/gpt-oss" }
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: browser
          label: Browser Tool
          type: server
        - id: shell
          label: Command Tool
          type: server
        - id: code
          label: Code Tool
          type: server
      scenes:
        - title: Browser interaction
          description: >-
            The agent navigates a website using a standard browser action
            vocabulary: navigate, click, type.
          actors_visible: [agent, browser]
          messages:
            - from: agent
              to: browser
              label: navigate
              json_preview: '{"url":"https://example.com"}'
              json_full: |
                {
                  "tool": "browser",
                  "action": "navigate",
                  "url": "https://example.com"
                }
            - from: browser
              to: agent
              label: page loaded
              json_preview: '{"title":"Example Domain"}'
              json_full: |
                {
                  "status": "ok",
                  "title": "Example Domain",
                  "url": "https://example.com",
                  "content": "This domain is for use in illustrative examples ..."
                }
        - title: Command execution
          description: >-
            The same agent switches to a shell tool using a familiar
            run/exit/stdout pattern.
          actors_visible: [agent, shell]
          sparkle: true
          messages:
            - from: agent
              to: shell
              label: run
              json_preview: '{"command":"ls"}'
              json_full: |
                {
                  "tool": "shell",
                  "command": "ls",
                  "working_directory": "/home/user/project"
                }
            - from: shell
              to: agent
              label: result
              json_preview: '{"exit_code":0,"stdout":"README.md\nsrc/\ntests/"}'
              json_full: |
                {
                  "exit_code": 0,
                  "stdout": "README.md\nsrc/\ntests/\npackage.json",
                  "stderr": ""
                }
        - title: Code execution
          description: >-
            The agent runs code in a sandboxed interpreter for
            computation, data analysis, or testing logic.
          actors_visible: [agent, code]
          messages:
            - from: agent
              to: code
              label: execute
              json_preview: '{"language":"python","code":"print(2+2)"}'
              json_full: |
                {
                  "tool": "code",
                  "language": "python",
                  "code": "print(2 + 2)"
                }
            - from: code
              to: agent
              label: output
              json_preview: '{"exit_code":0,"stdout":"4"}'
              json_full: |
                {
                  "exit_code": 0,
                  "stdout": "4",
                  "stderr": ""
                }

  # ── Instruction Surfaces ──────────────────────────────────────────
  - id: agents-md
    title: AGENTS.md
    icon_alt: "#"
    tagline: Project-local guidance for agents
    detail:
      links:
        - { label: "Standard", url: "https://agents.md/" }
      what_it_solves: >-
        Now that they can reliably read files and directories, coding agents are
        dropped into unfamiliar repositories and need to know:
        how do I build this? What style conventions matter? What should I
        never touch? Rebuilding this context for each request is inefficient.
        AGENTS.md gives them a predictable, standardized
        place to find project-specific instructions.
      how_its_standardizing: >-
        Community-driven format that emerged from the practice of
        embedding agent instructions in READMEs. Later formalized with a
        public spec and conventions for sections. Reported adoption
        across 60,000+ projects per agents.md tracking.
      virtuous_cycle:
        - "Repo maintainers put instructions in a standard place as they move from tool to tool."
        - "Tool makers start to look in that place to make their tool easier to adopt."
    animation:
      actors:
        - id: agent
          label: Coding Agent
          type: agent
        - id: agent-b
          label: Other Agent
          type: agent
        - id: repo-a
          label: Project Alpha
          type: repo
        - id: repo-b
          label: Project Beta
          type: repo
      scenes:
        - title: Agent opens a repo
          description: >-
            A coding agent is dropped into a repository. It looks for
            AGENTS.md at the project root.
          actors_visible: [agent, repo-a]
          messages:
            - from: agent
              to: repo-a
              label: Read AGENTS.md
              json_preview: 'GET /AGENTS.md'
            - from: repo-a
              to: agent
              label: Project instructions
              json_preview: '## Setup\n- `uv sync && uv run pytest`\n## Style\n- Run ruff format'
              json_full: |
                # AGENTS.md

                ## Setup
                - `uv sync`
                - `uv run pytest`

                ## How to work
                - Prefer small PRs.
                - Run `ruff format` before commit.

                ## Boundaries
                - Never change prod credentials handling without a reviewer.
        - title: Agent follows the instructions
          description: >-
            The agent reads the setup, style, and boundary sections,
            then works within those constraints automatically.
          actors_visible: [agent, repo-a]
          messages:
            - from: agent
              to: repo-a
              label: Runs setup
              json_preview: '$ uv sync && uv run pytest'
            - from: agent
              to: repo-a
              label: Follows style
              json_preview: '$ ruff format src/'
        - title: Different repo, same convention
          description: >-
            The agent moves to a completely different project. It finds
            another AGENTS.md and adapts immediately — no reconfiguration.
          actors_visible: [agent, repo-b]
          sparkle: true
          messages:
            - from: agent
              to: repo-b
              label: Read AGENTS.md
              json_preview: 'GET /AGENTS.md'
            - from: repo-b
              to: agent
              label: Different instructions
              json_preview: '## Setup\n- `npm install && npm test`\n## Style\n- Use TypeScript strict'
        - title: Different agent, same repo
          description: >-
            A completely different coding agent opens the same project.
            Same AGENTS.md, same instructions — write once, any agent reads.
          actors_visible: [agent-b, repo-a]
          sparkle: true
          messages:
            - from: agent-b
              to: repo-a
              label: Read AGENTS.md
              json_preview: 'GET /AGENTS.md'
            - from: repo-a
              to: agent-b
              label: Same instructions
              json_preview: '## Setup\n- `uv sync && uv run pytest`\n## Style\n- Run ruff format'

  - id: llms-txt
    title: llms.txt
    icon_alt: "//"
    tagline: AI-readable site index
    detail:
      links:
        - { label: "Standard", url: "https://llmstxt.org/" }
      what_it_solves: >-
        Model knowledge is frozen when the model is trained, but an agent might need more recent information,
        such as the documentation for a software library that hadn't been released yet when the model was trained.
        Agents can use web browsers to fetch that information, but browsing around for the right pages, fetching
        web pages designed for humans,
        and then extracting the information they need, is inefficient both for the agents and for the websites.
        llms.txt is a simple Markdown index at a well-known URL that
        tells agents where to look for key information designed for them to read.
      how_its_standardizing: >-
        Proposed by Jeremy Howard (September 2024). Adopted by
        documentation platforms and developer tools, with growing
        ecosystem support for auto-generating llms.txt files from
        existing site content.
      virtuous_cycle:
        - "Agents that know to use llms.txt spend fewer tokens and fetch fewer pages for more accurate information."
        - "Websites for services that want to be used by agents add llms.txt to encourage their use."
        - "Tools for publishing documentation add automatic generators; adoption becomes near-zero effort."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: site-a
          label: docs.example.com
          type: website
        - id: site-b
          label: api.other.dev
          type: website
      scenes:
        - title: Agent needs documentation
          description: >-
            An agent needs to understand an API. Instead of crawling
            the whole site, it fetches /llms.txt for a curated index.
          actors_visible: [agent, site-a]
          messages:
            - from: agent
              to: site-a
              label: Fetch /llms.txt
              json_preview: 'GET /llms.txt'
            - from: site-a
              to: agent
              label: Structured index
              json_preview: '# docs.example.com\n## Docs\n- /docs/getting-started\n- /docs/api'
              json_full: |
                # docs.example.com

                ## Docs
                - /docs/getting-started
                - /docs/api

                ## Canonical specs
                - /docs/protocol
                - /docs/security

                ## Examples
                - /docs/examples/basic
        - title: Agent fetches exactly what it needs
          description: >-
            With the index, the agent knows precisely which pages to
            read — no wasted tokens on irrelevant content.
          actors_visible: [agent, site-a]
          messages:
            - from: agent
              to: site-a
              label: Fetch specific page
              json_preview: 'GET /docs/api'
            - from: site-a
              to: agent
              label: Focused content
              json_preview: '# API Reference\n## Authentication\nUse Bearer tokens...'
        - title: Works on any site
          description: >-
            A different website also publishes llms.txt. The agent
            uses the same approach — one convention, every site.
          actors_visible: [agent, site-b]
          sparkle: true
          messages:
            - from: agent
              to: site-b
              label: Fetch /llms.txt
              json_preview: 'GET /llms.txt'
            - from: site-b
              to: agent
              label: Structured index
              json_preview: '# api.other.dev\n## Endpoints\n- /reference/auth\n- /reference/users'

  - id: agent-skills
    title: Agent Skills
    icon_alt: "pkg"
    tagline: Portable capability packages
    detail:
      links:
        - { label: "Standard", url: "https://agentskills.io/specification" }
        - { label: "Codex skills docs", url: "https://developers.openai.com/codex/skills/" }
      what_it_solves: >-
        As agents grew beyond a handful of tools, two problems emerged:
        (1) reliability and consistency: teams and communities wanted to share and improve
        increasingly long and specific prompts to handle particular situations; and
        (2) scale: agents need dozens or hundreds of reusable procedures,
        scripts, and references without bloating every run's context. Agent skills package
        task-specific playbooks (and optional scripts/resources) so an agent framework can load
        just the metadata up front, then pull full instructions and files only when the
        task calls for them.
      how_its_standardizing: >-
        The format was developed in the Anthropic ecosystem (notably Claude Code) and
        released as an open standard. OpenAI's Codex
        built on the open Agent Skills standard,
        and vendors published cross-agent skill repos (e.g., Cloudflare). Agent frameworks are converging on common local install locations and emerging “well-known” publishing patterns.
      virtuous_cycle:
        - "Users working within a particular agent ecosystem develop a way to share skills with each other."
        - "Builders of other agent ecosystems add support for the same format to benefit from the shared skills."
        - "Users benefit from sharing skills across ecosystems."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: site-a
          label: docs.example.com
          type: website
        - id: site-b
          label: api.other.dev
          type: website
      scenes:
        - title: Host discovers installed skills (metadata only)
          description: >-
            At startup, hosts scan a known local skills directory and load only the
            SKILL.md frontmatter (name + description) for every skill.
          actors_visible: [host, skills-dir]
          messages:
            - from: host
              to: skills-dir
              label: Scan skills directory
              json_preview: 'list ~/.config/agent/skills/*/SKILL.md'
            - from: skills-dir
              to: host
              label: Read frontmatter only
              json_preview: '[{"name":"weather","description":"Look up current weather"}]'
              json_full: |
                ~/.config/agent/skills/
                  weather/
                    SKILL.md
                    scripts/get_weather.py
                    references/open-meteo.md

                ---
                name: weather
                description: Look up current weather for a location.
                ---

        - title: Host activates a skill (load instructions on demand)
          description: >-
            When a task matches, the host loads the full SKILL.md instructions and
            any referenced files as needed (scripts, references).
          actors_visible: [host, skill]
          messages:
            - from: host
              to: skill
              label: Load SKILL.md body
              json_preview: 'Read skills/weather/SKILL.md (full)'
              json_full: |
                ---
                name: weather
                description: Look up current weather for a location.
                ---

                ## Inputs
                - location (string)

                ## Output
                - JSON: { "temp_c": number, "summary": string }

                ## Steps
                1. Run scripts/get_weather.py with the location.
                2. If API errors occur, consult references/open-meteo.md.

            - from: host
              to: skill
              label: Run skill script
              json_preview: '$ python scripts/get_weather.py --location "Boston, MA"'

        - title: Same skill works in different agent products
          description: >-
            Because the directory + SKILL.md contract is shared, different hosts can
            install the same skill bundle without rewriting it.
          actors_visible: [skill, host]
          sparkle: true
          messages:
            - from: host
              to: skill
              label: Install skill bundle
              json_preview: 'install cloudflare/skills (Agent Skills format)'
            - from: skill
              to: host
              label: Ready
              json_preview: 'discovered: name="weather"'

  - id: agent-skills-discovery
    title: Agent Skills Discovery
    icon_alt: "compass"
    tagline: Find skills published by a trusted website
    detail:
      links:
        - { label: "Cloudflare: Agent Skills Discovery RFC", url: "https://github.com/cloudflare/agent-skills-discovery-rfc" }
        - { label: "Mintlify: Skills discovery from any URL", url: "https://www.mintlify.com/blog/skills-discovery-from-any-url" }
        - { label: "RFC 8615 (.well-known)", url: "https://www.rfc-editor.org/rfc/rfc8615" }
      what_it_solves: >-
        The Agent Skills format standardizes a skill bundle on disk, but it doesn't
        answer: “given a docs or product URL, where are the skills for this thing?”
        Skills Discovery adds an llms.txt-like discovery mechanism: a predictable
        well-known index that lists the skills published by that site or docs root.
      how_its_standardizing: >-
        Cloudflare's RFC proposes serving a JSON index under `/.well-known/skills/`
        (built on RFC 8615). Tooling has started to implement it in practice: e.g.,
        Mintlify auto-serves the index for docs sites and a CLI can install skills
        from a URL without knowing repository structure.
      virtuous_cycle:
        - "Sites publish a predictable index; agents fetch fewer pages and waste fewer tokens."
        - "CLIs/hosts can 'add skill from URL' with one convention instead of bespoke scraping."
        - "More publishers adopt it because it becomes the default way agents learn products."
    animation:
      actors:
        - id: agent
          label: Agent Host / CLI
          type: agent
        - id: site
          label: docs.example.com
          type: website
        - id: skills
          label: Local Skills Folder
          type: repo
      scenes:
        - title: Fetch the well-known skills index
          description: >-
            The host is given a docs URL and looks for a predictable index under
            `/.well-known/skills/` to learn what skills exist for that site.
          actors_visible: [agent, site]
          messages:
            - from: agent
              to: site
              label: GET index.json
              json_preview: 'GET /docs/.well-known/skills/index.json'
            - from: site
              to: agent
              label: Available skills
              json_preview: '{"skills":[{"name":"payments","description":"Integrate checkout","files":["SKILL.md"]}]}'
        - title: Install to the local skills directory
          description: >-
            The host downloads the listed files and installs the bundle into the
            standard local skills location for immediate use.
          actors_visible: [agent, skills]
          sparkle: true
          messages:
            - from: agent
              to: site
              label: Fetch SKILL.md
              json_preview: 'GET /docs/.well-known/skills/payments/SKILL.md'
            - from: agent
              to: skills
              label: Write local skill bundle
              json_preview: 'write ~/.config/agent/skills/payments/SKILL.md'


  - id: agent-skills-registries
    title: Agent Skills Registries
    icon_alt: "dir"
    tagline: npm-style catalogs for skills
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Solo.io: agentregistry launch", url: "https://www.solo.io/press-releases/agent-skills-kubernetes-ecosystem" }
        - { label: "Solo.io Lab: Introduction to agentregistry", url: "https://www.solo.io/resources/lab/introduction-to-agentregistry" }
        - { label: "Agent Skills spec (package format)", url: "https://agentskills.io/specification" }
      what_it_solves: >-
        As agent skills proliferate, users will want to find popular and well supported skills for specific tasks
        ("what are the best skills for checking website accessibility?"). And as agents become more self-sufficient,
        users may want them to go out and discover their own high quality skills as needed, rather than be limited to skills predicted by the agent's developer.
        Skills registries would enable search, versions, metadata, curation, and organization-wide distribution,
        similar to package managers for software libraries like npm or PyPI. This (we can hope!) also becomes the natural home for provenance, permissions, and policy metadata.
      how_its_standardizing: >-
        Registry behavior is emerging via vendor/open-source projects (e.g., Solo.io's
        agentregistry or ClawHub.ai) that store skills and MCP servers with metadata, pull/install
        workflows, and enterprise distribution patterns. A shared registry protocol
        is not yet settled; convergence pressure will likely focus on a common
        "package + manifest + fetch" surface layered on the Agent Skills bundle format.
      virtuous_cycle:
        - "Publishers ship one artifact; many hosts can search and install it."
        - "Organizations centralize distribution and policy instead of copying files around."
        - "Security metadata (signing, permissions, sandbox expectations, trust relationships) enables use by more cautious users."
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: agent
        - id: registry
          label: Skills Registry
          type: registry
        - id: skills
          label: Local Skills Folder
          type: repo
      scenes:
        - title: Search the registry for a skill
          description: >-
            The host queries a registry by task/keyword and gets back candidate skills
            with versions and basic metadata.
          actors_visible: [agent, registry]
          messages:
            - from: agent
              to: registry
              label: search
              json_preview: '{"q":"checkout integration","limit":5}'
            - from: registry
              to: agent
              label: results
              json_preview: '[{"name":"payments","version":"1.2.0","summary":"Integrate checkout flows"}]'
        - title: Pull and install (policy to be worked out)
          description: >-
            The host downloads the selected skill bundle and installs it locally.
            Registries are the natural place to attach provenance/permissions later.
          actors_visible: [agent, registry, skills]
          sparkle: true
          messages:
            - from: agent
              to: registry
              label: pull
              json_preview: '{"name":"payments","version":"1.2.0"}'
            - from: registry
              to: agent
              label: bundle + manifest
              json_preview: '{"files":["SKILL.md","scripts/checkout.py"],"manifest":"..."}'
            - from: agent
              to: skills
              label: install
              json_preview: 'write ~/.config/agent/skills/payments/...'

  # ── Agent Loop ──────────────────────────────────────────────────────
  - id: agent-loop
    title: Agent Loop
    icon_alt: "loop"
    tagline: Models that keep going
    detail:
      links:
        - { label: "Pattern", url: "https://www.anthropic.com/engineering/building-effective-agents" }
        - { label: "goose (described as a 'reference implementation' contributed to the Linux Foundation)", url: "https://block.xyz/inside/block-anthropic-and-openai-launch-the-agentic-ai-foundation" }
      what_it_solves: >-
        Tool calling lets a model request one action — but real tasks require
        many steps. The agent loop is the pattern of repeatedly calling the
        model, executing its tool requests, feeding results back, and continuing
        until the model signals completion. This loop turns a chat model into
        an autonomous agent.
      how_its_standardizing: >-
        De facto convergence across agent frameworks (LangChain, AutoGPT,
        Claude computer use, OpenAI Assistants). The pattern is consistent:
        system prompt + user goal, model responds with tool calls or final
        answer, host executes and re-prompts. No formal spec, but the shape
        is universal.
      virtuous_cycle:
        - "Developers build on the pattern rather than inventing custom control flows."
        - "Models are trained to emit stop signals and multi-step plans reliably."
        - "Tooling (tracing, guardrails, timeouts) targets a predictable execution model."
    animation:
      actors:
        - id: agent
          label: Agent Host
          type: agent
        - id: model
          label: Model
          type: model
        - id: tool
          label: Tool
          type: server
      scenes:
        - title: Plan
          description: >-
            The agent asks the model what to do next given the current state.
          actors_visible: [agent, model]
          messages:
            - from: agent
              to: model
              label: prompt
              json_preview: '{"goal":"Fix failing tests"}'
        - title: Act
          description: >-
            The model emits a tool call; the host executes it.
          actors_visible: [agent, model, tool]
          messages:
            - from: model
              to: agent
              label: tool_call
              json_preview: '{"name":"run_tests"}'
            - from: agent
              to: tool
              label: execute
              json_preview: '{"cmd":"pytest"}'
        - title: Iterate
          description: >-
            Results are fed back into the model, continuing the loop
            until completion.
          actors_visible: [agent, model]
          sparkle: true
          messages:
            - from: agent
              to: model
              label: result
              json_preview: '{"failures":0}'

  # ── A2A ───────────────────────────────────────────────────────────
  - id: a2a
    title: A2A
    icon_alt: "<>"
    tagline: Agents working across frameworks
    detail:
      links:
        - { label: "Launch", url: "https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/" }
        - { label: "Specification", url: "https://agent2agent.info/specification/" }
        - { label: "Linux Foundation", url: "https://www.linuxfoundation.org/projects/agent2agent" }
      what_it_solves: >-
        Agents built on different frameworks — by different vendors — need
        to discover each other, negotiate capabilities, and coordinate on
        tasks. A2A provides a standard protocol for agent-to-agent
        interoperability without requiring shared internals.
      how_its_standardizing: >-
        Announced by Google (April 2025). Quickly moved to open
        governance under the Linux Foundation. Implemented by multiple
        platforms; Microsoft ecosystem documentation positions it as a
        standard integration surface.
      virtuous_cycle:
        - "Enterprises can compose agents across vendors instead of buying a monolith."
        - "Vendors become more valuable by being interoperable, not isolated."
        - "A shared task/artifact model enables tooling (routers, registries, monitors)."
    animation:
      actors:
        - id: client
          label: Your Agent
          type: agent
        - id: invoice-agent
          label: Invoice Agent
          type: agent
        - id: research-agent
          label: Research Agent
          type: agent
      scenes:
        - title: Discover a remote agent
          description: >-
            Your agent fetches the remote agent's AgentCard — a JSON
            file at a well-known URL describing capabilities and skills.
          actors_visible: [client, invoice-agent]
          messages:
            - from: client
              to: invoice-agent
              label: Fetch AgentCard
              json_preview: 'GET /.well-known/agent-card.json'
            - from: invoice-agent
              to: client
              label: Capabilities
              json_preview: '{"name":"InvoiceAgent","skills":[{"id":"extract","name":"Extract invoice"}]}'
              json_full: |
                {
                  "name": "InvoiceAgent",
                  "description": "Extracts invoice fields from PDFs",
                  "url": "https://agent.example/a2a",
                  "provider": {
                    "organization": "ExampleCo",
                    "url": "https://example.com"
                  },
                  "version": "1.0.0",
                  "capabilities": {
                    "streaming": true,
                    "pushNotifications": false,
                    "stateTransitionHistory": true
                  },
                  "authentication": {"schemes": ["Bearer"]},
                  "defaultInputModes": ["application/pdf", "text/plain"],
                  "defaultOutputModes": ["application/json"],
                  "skills": [{
                    "id": "extract",
                    "name": "Extract invoice",
                    "description": "Parse invoice fields from documents",
                    "tags": ["ap"],
                    "examples": ["Extract totals from this PDF"]
                  }]
                }
        - title: Send a task
          description: >-
            Your agent sends a task with messages. The remote agent
            processes it and returns artifacts.
          actors_visible: [client, invoice-agent]
          messages:
            - from: client
              to: invoice-agent
              label: Submit task
              json_preview: '{"task":{"id":"t-123","state":"submitted"},"messages":[{"role":"user","parts":[...]}]}'
              json_full: |
                {
                  "task": {
                    "id": "t-123",
                    "state": "submitted"
                  },
                  "messages": [{
                    "role": "user",
                    "parts": [{
                      "content_type": "text/plain",
                      "content": "Extract invoice fields from https://example.com/inv.pdf"
                    }]
                  }]
                }
            - from: invoice-agent
              to: client
              label: Task artifacts
              json_preview: '{"task":{"state":"completed"},"artifacts":[{"parts":[{"content":"{...}"}]}]}'
        - title: Different agent, same protocol
          description: >-
            Your agent discovers a Research Agent at a different
            organization. Same AgentCard format, same task protocol.
          actors_visible: [client, research-agent]
          sparkle: true
          messages:
            - from: client
              to: research-agent
              label: Fetch AgentCard
              json_preview: 'GET /.well-known/agent-card.json'
            - from: research-agent
              to: client
              label: Capabilities
              json_preview: '{"name":"ResearchAgent","skills":[{"id":"search","name":"Deep research"}]}'

  # ── Domain Protocols ──────────────────────────────────────────────
  - id: ucp
    title: UCP
    icon_alt: "$"
    tagline: Universal agent commerce
    detail:
      links:
        - { label: "Shopify launch", url: "https://www.shopify.com/ucp" }
        - { label: "Google explainer", url: "https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/" }
      what_it_solves: >-
        Agents that shop need a standard way to browse products, build
        carts, and complete checkout across different merchants — without
        custom integration per store. UCP defines capabilities discovery,
        checkout sessions, and payment handlers for agent commerce.
      how_its_standardizing: >-
        Launched January 2026 by Shopify and Google. Specifies capability
        negotiation, checkout session creation, and payment handler
        interfaces. Supported by large retailers and payments ecosystem
        partners. Open for any merchant, agent, or payment processor.
      virtuous_cycle:
        - "Merchants implement once and accept many agents."
        - "Agents implement once and can shop broadly."
        - "Payments/logistics partners standardize integrations around a common flow."
    animation:
      actors:
        - id: agent
          label: Shopping Agent
          type: agent
        - id: merchant-a
          label: Flower Shop
          type: merchant
        - id: merchant-b
          label: Book Store
          type: merchant
      scenes:
        - title: Agent creates a checkout
          description: >-
            The shopping agent creates a checkout session with a
            merchant, sending line items and buyer info.
          actors_visible: [agent, merchant-a]
          messages:
            - from: agent
              to: merchant-a
              label: Create checkout session
              json_preview: '{"line_items":[{"item":{"id":"bouquet_roses"},"quantity":1}],"currency":"USD"}'
              json_full: |
                POST /checkout-sessions
                UCP-Agent: profile="https://agent.example/profile"
                {
                  "line_items": [{
                    "item": {"id": "bouquet_roses", "title": "Red Rose Bouquet"},
                    "quantity": 1
                  }],
                  "buyer": {
                    "full_name": "John Doe",
                    "email": "john.doe@example.com"
                  },
                  "currency": "USD",
                  "payment": {
                    "instruments": [],
                    "handlers": [{
                      "id": "shop_pay",
                      "name": "com.shopify.shop_pay",
                      "version": "2026-01-11"
                    }]
                  }
                }
            - from: merchant-a
              to: agent
              label: Session ready
              json_preview: '{"id":"session-abc","status":"ready_for_complete","total":"$49.99"}'
              json_full: |
                {
                  "ucp": {
                    "version": "2026-01-11",
                    "capabilities": [{
                      "name": "dev.ucp.shopping.checkout",
                      "version": "2026-01-11"
                    }]
                  },
                  "id": "session-abc",
                  "status": "ready_for_complete",
                  "total": {"amount": 4999, "currency": "USD"}
                }
        - title: Agent completes purchase
          description: >-
            The agent confirms the purchase. The merchant processes
            payment and returns an order confirmation.
          actors_visible: [agent, merchant-a]
          messages:
            - from: agent
              to: merchant-a
              label: Complete checkout
              json_preview: '{"session_id":"session-abc","action":"complete"}'
            - from: merchant-a
              to: agent
              label: Order confirmed
              json_preview: '{"order_id":"ord-789","status":"confirmed"}'
        - title: Same protocol, different merchant
          description: >-
            The agent shops at a completely different store. Same
            checkout flow, same API shape — no new integration needed.
          actors_visible: [agent, merchant-b]
          sparkle: true
          messages:
            - from: agent
              to: merchant-b
              label: Create checkout session
              json_preview: '{"line_items":[{"item":{"id":"novel_123"},"quantity":2}],"currency":"USD"}'
            - from: merchant-b
              to: agent
              label: Session ready
              json_preview: '{"id":"session-xyz","status":"ready_for_complete","total":"$31.98"}'

  - id: agent-identity
    title: Agent Identity
    icon_alt: "id"
    tagline: Verified agents on the open web
    detail:
      links:
        - { label: "HTTP Message Signatures (IETF)", url: "https://datatracker.ietf.org/wg/httpbis/documents/" }
        - { label: "Cloudflare Web Bot Auth", url: "https://blog.cloudflare.com/secure-agentic-commerce/" }
        - { label: "Visa TAP", url: "https://developer.visa.com/capabilities/trusted-agent-protocol/trusted-agent-protocol-specifications" }
      what_it_solves: >-
        Websites and merchants need to distinguish legitimate,
        user-authorized agents from scrapers and bots. Agent Identity
        protocols use cryptographic signatures to prove an agent's
        identity on every request — no CAPTCHAs, no IP allowlists.
      how_its_standardizing: >-
        Built on HTTP Message Signatures (IETF standards track) as the
        base primitive. Domain profiles add agent-specific semantics:
        Cloudflare's Web Bot Auth and Visa's Trusted Agent Protocol (TAP)
        both use the same signature foundation with different registry
        and tagging conventions for their ecosystems.
      virtuous_cycle:
        - "Sites can apply policy based on verified identity rather than guesswork."
        - "Agents get reliable access without adversarial bot mitigation."
        - "Commerce and high-trust domains get a shared trust substrate."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: merchant
          label: Merchant Site
          type: merchant
        - id: registry
          label: Key Registry
          type: registry
      scenes:
        - title: Agent signs its request
          description: >-
            The agent makes an HTTP request and attaches a
            cryptographic signature using HTTP Message Signatures.
          actors_visible: [agent, merchant]
          messages:
            - from: agent
              to: merchant
              label: Signed request
              json_preview: 'Signature-Input: sig2=("@authority" "@path");keyid="...";tag="agent-browser-auth"'
              json_full: |
                GET /example-product HTTP/1.1
                Host: example.com
                Signature-Input: sig2=("@authority" "@path");created=1735689600;
                  expires=1735693200;keyid="agent-key-123";
                  alg="Ed25519";nonce="abc123";
                  tag="agent-browser-auth"
                Signature: sig2=:BASE64_SIGNATURE_HERE:
        - title: Merchant verifies identity
          description: >-
            The merchant retrieves the agent's public key and verifies
            the signature. Legitimate agents get through; unknown bots don't.
          actors_visible: [agent, merchant, registry]
          messages:
            - from: merchant
              to: registry
              label: Fetch public key
              json_preview: 'GET /.well-known/agent-keys/agent-key-123'
            - from: registry
              to: merchant
              label: Public key
              json_preview: '{"keyid":"agent-key-123","alg":"Ed25519","public_key":"..."}'
            - from: merchant
              to: agent
              label: Access granted
              json_preview: 'HTTP/1.1 200 OK'
        - title: Same signatures work everywhere
          description: >-
            Whether it's Visa TAP, Cloudflare Web Bot Auth, or
            Mastercard Agent Pay — the same HTTP Message Signatures
            standard works across all of them.
          actors_visible: [agent, merchant]
          sparkle: true
          messages:
            - from: agent
              to: merchant
              label: 'Signed: tag="web-bot-auth"'
              json_preview: 'Signature-Input: sig2=("@authority" "@path");tag="web-bot-auth"'
            - from: merchant
              to: agent
              label: Verified
              json_preview: 'HTTP/1.1 200 OK — Agent identity confirmed'

  # ── Frontier (locked by default; rocket unlocks) ──────────────────
  - id: agent-audit
    title: Agent Audit Traces
    icon_alt: "log"
    tagline: Portable run records
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Standard (substrate)", url: "https://opentelemetry.io/docs/concepts/signals/traces/" }
      what_it_solves: >-
        A standard event+artifact record of what an agent did (model calls,
        tool calls, browser actions, file writes) for replay, debugging,
        and incident response.
      how_its_standardizing: >-
        Likely to layer on OpenTelemetry-like traces with agent-specific
        event schemas, redaction, and artifact references.
      virtuous_cycle:
        - "Operators can debug and govern agents across vendors with one trace format."
        - "Vendors integrate once with monitoring and compliance tooling."
        - "Evaluations and safety reviews become reproducible and comparable."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: trace
          label: Trace Store
          type: server
      scenes:
        - title: Emit trace events
          description: >-
            Each model call and tool action is recorded as a structured
            trace event.
          actors_visible: [agent, trace]
          messages:
            - from: agent
              to: trace
              label: span
              json_preview: '{"event":"tool_call","name":"read_file"}'

  - id: ap2
    title: AP2
    icon_alt: "pay"
    tagline: Agent-to-agent payments
    detail:
      links:
        - { label: "Specification", url: "https://ap2-protocol.org/specification/" }
      what_it_solves: >-
        Agents that transact on behalf of users need a standard way to
        request, authorize, and settle payments — with cryptographic
        proof of user consent and spending limits. AP2 defines payment
        mandates that bind user intent to agent actions.
      how_its_standardizing: >-
        Open specification for agent-initiated payments. Defines mandate
        objects with scope, limits, and TTL that travel with payment
        requests. Designed to work alongside identity protocols like
        TAP and Web Bot Auth.
      virtuous_cycle:
        - "Agents can transact across merchants with verifiable authorization."
        - "Merchants get cryptographic proof of user consent, reducing fraud."
        - "Payment rails gain a standard agent interface instead of per-agent integrations."
    animation:
      actors:
        - id: agent
          label: Paying Agent
          type: agent
        - id: merchant
          label: Merchant
          type: merchant
        - id: wallet
          label: Wallet
          type: server
      scenes:
        - title: Present payment mandate
          description: >-
            The agent submits a signed mandate proving user authorization
            and spending limits.
          actors_visible: [agent, merchant]
          messages:
            - from: agent
              to: merchant
              label: pay
              json_preview: '{"mandate_id":"m-123","amount":4999}'
        - title: Settle payment
          description: >-
            The merchant verifies the mandate and settles through a
            compatible payment rail.
          actors_visible: [merchant, wallet]
          sparkle: true
          messages:
            - from: merchant
              to: wallet
              label: charge
              json_preview: '{"mandate_id":"m-123"}'

  - id: intent-mandates
    title: Signed Intent Mandates
    icon_alt: "sig"
    tagline: Verifiable consent for actions
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Inspiration (AP2)", url: "https://ap2-protocol.org/specification/" }
      what_it_solves: >-
        A signed object binding user intent and constraints (scope, limits,
        TTL) to downstream agent actions — generalizing the "payments
        mandate" pattern from AP2 to arbitrary domains.
      how_its_standardizing: >-
        Expected to converge first in regulated domains (payments, IT ops,
        healthcare), then generalize to cross-domain consent receipts with
        standard fields. AP2's payment mandates provide the reference design.
      virtuous_cycle:
        - "Counterparties can rely on machine-verifiable authorization."
        - "Users get enforceable constraints instead of trusting opaque agents."
        - "Platforms interoperate on the same consent artifact across workflows."
    animation:
      actors:
        - id: user
          label: User
          type: app
        - id: agent
          label: Agent
          type: agent
        - id: service
          label: Service
          type: server
      scenes:
        - title: User signs intent
          description: >-
            The user signs an intent object defining scope, limits,
            and expiration.
          actors_visible: [user, agent]
          messages:
            - from: user
              to: agent
              label: sign
              json_preview: '{"action":"deploy","ttl":"1h"}'
        - title: Agent presents mandate
          description: >-
            The agent attaches the signed mandate to downstream requests.
          actors_visible: [agent, service]
          sparkle: true
          messages:
            - from: agent
              to: service
              label: authorized request
              json_preview: '{"mandate":"signed_blob"}'

  - id: agent-card
    title: AgentCard
    icon_alt: "card"
    tagline: Well-known agent descriptors
    detail:
      links:
        - { label: "A2A AgentCard spec", url: "https://agent2agent.info/specification/#agentcard" }
      what_it_solves: >-
        Before agents can collaborate, they need to discover each other's
        capabilities, endpoints, and authentication requirements. AgentCard
        is a JSON descriptor at a well-known URL that tells other agents
        what this agent can do and how to talk to it.
      how_its_standardizing: >-
        Defined as part of A2A. Agents publish a JSON file at
        /.well-known/agent-card.json describing name, skills, supported
        input/output modes, and auth schemes. Provides the discovery
        primitive that higher-level registries can index.
      virtuous_cycle:
        - "Agents can discover each other without a central directory."
        - "Registries index the same descriptor format across vendors."
        - "A standard metadata shape enables tooling (routers, monitors, catalogs)."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: remote
          label: Remote Agent
          type: agent
      scenes:
        - title: Discover capabilities
          description: >-
            An agent fetches a remote agent's well-known AgentCard
            descriptor.
          actors_visible: [agent, remote]
          messages:
            - from: agent
              to: remote
              label: GET /.well-known/agent-card.json
              json_preview: '{}'
            - from: remote
              to: agent
              label: AgentCard
              json_preview: '{"skills":["search","summarize"]}'

  - id: agent-registries
    title: Agent Registries
    icon_alt: "dir"
    tagline: Discovery, routing, permissions
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Draft (example)", url: "https://datatracker.ietf.org/doc/draft-narvaneni-agent-uri/" }
      what_it_solves: >-
        A standard directory for agents: capability queries, routing,
        health/versioning, and enterprise entitlements.
      how_its_standardizing: >-
        Likely to emerge from enterprise catalogs and public indexes
        that aggregate AgentCard descriptors. A2A's well-known discovery
        provides the base layer; registries add search, ACLs, and routing.
      virtuous_cycle:
        - "Enterprises can safely compose multi-vendor agent systems."
        - "Vendors plug into one directory surface instead of bespoke integrations."
        - "Governance (who can call what) becomes portable."
    animation:
      actors:
        - id: agent
          label: Agent
          type: agent
        - id: registry
          label: Registry
          type: registry
      scenes:
        - title: Query registry
          description: >-
            An agent searches a registry for other agents matching
            required capabilities.
          actors_visible: [agent, registry]
          messages:
            - from: agent
              to: registry
              label: search
              json_preview: '{"skill":"invoice-extraction"}'
            - from: registry
              to: agent
              label: results
              json_preview: '[{"agent":"InvoiceAgent"}]'

  - id: agent-lingua
    title: Agent Lingua Franca
    icon_alt: "abc"
    tagline: Token-efficient inter-agent speech
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Research (inspiration)", url: "https://arxiv.org/abs/2310.06562" }
      what_it_solves: >-
        When agents communicate, they use verbose natural language or structured
        JSON — neither optimized for inter-agent bandwidth. A shared compressed
        vocabulary or symbolic language could dramatically reduce token costs
        while preserving semantics across different models and tokenizers.
      how_its_standardizing: >-
        Expected to emerge as multi-agent orchestration scales and costs matter.
        Could layer compression codebooks on A2A, develop learned shorthand via
        multi-agent RL, or converge on symbolic representations that transcend
        natural language tokenization boundaries.
      virtuous_cycle:
        - "Multi-agent workflows become economical as token overhead shrinks."
        - "Heterogeneous model teams communicate efficiently despite different tokenizers."
        - "Shared vocabularies enable richer coordination primitives than natural language."
    animation:
      actors:
        - id: agent-a
          label: Agent A
          type: agent
        - id: agent-b
          label: Agent B
          type: agent
      scenes:
        - title: Compressed exchange
          description: >-
            Agents communicate using a shared compressed representation
            instead of natural language.
          actors_visible: [agent-a, agent-b]
          sparkle: true
          messages:
            - from: agent-a
              to: agent-b
              label: message
              json_preview: '{"sym":"Δ7α"}'

  - id: human-context-protocol
    title: Human Context Protocol
    icon_alt: "ctx"
    tagline: Portable user memory and preferences
    unlock: { state: locked, class: frontier }
    detail:
      links:
        - { label: "Project", url: "https://digitaleconomy.stanford.edu/project/loyal-agents/hcp-human-context-protocol/" }
        - { label: "Paper", url: "https://digitaleconomy.stanford.edu/wp-content/uploads/2024/11/Loyal-Agents.pdf" }
      what_it_solves: >-
        Agents today manage user preferences, goals, and long-term context in
        ad hoc, vendor-specific memory systems. This makes it impossible for users
        to switch agents, combine agents, or delegate tasks across systems without
        losing intent, preferences, and consent. HCP defines a clean boundary
        between an agent and a user-aligned memory manager.
      how_its_standardizing: >-
        HCP is a research proposal from the Stanford Digital Economy Lab,
        not yet a formal specification. It proposes a conceptual protocol
        surface — schema definition, preference search, and preference update —
        between agents and external "human context" stores. Explicitly framed
        to enable cross-vendor interoperability and user-controlled memory
        portability if adopted.
      virtuous_cycle:
        - "Users gain portable, agent-agnostic preferences and long-term context."
        - "Agent builders can offload memory, consent, and personalization safely."
        - "Memory providers can specialize and compete without locking in agents."
    animation:
      actors:
        - id: agent
          label: AI Agent
          type: agent
        - id: memory-a
          label: Context Manager
          type: server
        - id: memory-b
          label: Other Provider
          type: server
      scenes:
        - title: Define preference schema
          description: >-
            The agent declares the structure of user preferences it may read or
            write, without embedding them directly in prompts.
          actors_visible: [agent, memory-a]
          messages:
            - from: agent
              to: memory-a
              label: Define schema
              json_preview: '{"namespace":"prefs","fields":["tone","units"]}'
        - title: Query human context
          description: >-
            The agent retrieves relevant preferences at runtime, scoped to the
            current task.
          actors_visible: [agent, memory-a]
          messages:
            - from: agent
              to: memory-a
              label: Search prefs
              json_preview: '{"query":"units","top_k":1}'
            - from: memory-a
              to: agent
              label: Preference
              json_preview: '{"key":"units","value":"metric"}'
        - title: Swap memory provider
          description: >-
            A different HCP-compliant context manager can be used without changing
            the agent logic — user preferences travel with the user.
          actors_visible: [agent, memory-b]
          sparkle: true
          messages:
            - from: agent
              to: memory-b
              label: Search prefs
              json_preview: '{"query":"units","top_k":1}'
            - from: memory-b
              to: agent
              label: Same interface
              json_preview: '{"key":"units","value":"metric"}'
